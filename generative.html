<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Generative Models | Basics of Statistical Learning</title>
  <meta name="description" content="Chapter 10 Generative Models | Basics of Statistical Learning" />
  <meta name="generator" content="bookdown 0.21.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Generative Models | Basics of Statistical Learning" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://statisticallearning.org/" />
  
  
  <meta name="github-repo" content="daviddalpiaz/bsl" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Generative Models | Basics of Statistical Learning" />
  
  
  

<meta name="author" content="David Dalpiaz" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="binary-classification.html"/>
<link rel="next" href="cross-validation.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Basics of Statistical Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#who"><i class="fa fa-check"></i><b>0.1</b> Who?</a>
<ul>
<li class="chapter" data-level="0.1.1" data-path="index.html"><a href="index.html#readers"><i class="fa fa-check"></i><b>0.1.1</b> Readers</a></li>
<li class="chapter" data-level="0.1.2" data-path="index.html"><a href="index.html#author"><i class="fa fa-check"></i><b>0.1.2</b> Author</a></li>
<li class="chapter" data-level="0.1.3" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>0.1.3</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#what"><i class="fa fa-check"></i><b>0.2</b> What?</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#why"><i class="fa fa-check"></i><b>0.3</b> Why?</a></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#where"><i class="fa fa-check"></i><b>0.4</b> Where?</a></li>
<li class="chapter" data-level="0.5" data-path="index.html"><a href="index.html#when"><i class="fa fa-check"></i><b>0.5</b> When?</a></li>
<li class="chapter" data-level="0.6" data-path="index.html"><a href="index.html#how"><i class="fa fa-check"></i><b>0.6</b> How?</a>
<ul>
<li class="chapter" data-level="0.6.1" data-path="index.html"><a href="index.html#build-tools"><i class="fa fa-check"></i><b>0.6.1</b> Build Tools</a></li>
<li class="chapter" data-level="0.6.2" data-path="index.html"><a href="index.html#active-development"><i class="fa fa-check"></i><b>0.6.2</b> Active Development</a></li>
<li class="chapter" data-level="0.6.3" data-path="index.html"><a href="index.html#packages"><i class="fa fa-check"></i><b>0.6.3</b> Packages</a></li>
<li class="chapter" data-level="0.6.4" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i><b>0.6.4</b> License</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="ml-overview.html"><a href="ml-overview.html"><i class="fa fa-check"></i><b>1</b> Machine Learning Overview</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ml-overview.html"><a href="ml-overview.html#what-is-machine-learning"><i class="fa fa-check"></i><b>1.1</b> What is Machine Learning?</a></li>
<li class="chapter" data-level="1.2" data-path="ml-overview.html"><a href="ml-overview.html#machine-learning-tasks"><i class="fa fa-check"></i><b>1.2</b> Machine Learning Tasks</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="ml-overview.html"><a href="ml-overview.html#supervised-learning"><i class="fa fa-check"></i><b>1.2.1</b> Supervised Learning</a></li>
<li class="chapter" data-level="1.2.2" data-path="ml-overview.html"><a href="ml-overview.html#unsupervised-learning"><i class="fa fa-check"></i><b>1.2.2</b> Unsupervised Learning</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="ml-overview.html"><a href="ml-overview.html#open-questions"><i class="fa fa-check"></i><b>1.3</b> Open Questions</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>2</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="linear-regression.html"><a href="linear-regression.html#r-setup-and-source"><i class="fa fa-check"></i><b>2.1</b> R Setup and Source</a></li>
<li class="chapter" data-level="2.2" data-path="linear-regression.html"><a href="linear-regression.html#explanation-versus-prediction"><i class="fa fa-check"></i><b>2.2</b> Explanation versus Prediction</a></li>
<li class="chapter" data-level="2.3" data-path="linear-regression.html"><a href="linear-regression.html#task-setup"><i class="fa fa-check"></i><b>2.3</b> Task Setup</a></li>
<li class="chapter" data-level="2.4" data-path="linear-regression.html"><a href="linear-regression.html#mathematical-setup"><i class="fa fa-check"></i><b>2.4</b> Mathematical Setup</a></li>
<li class="chapter" data-level="2.5" data-path="linear-regression.html"><a href="linear-regression.html#linear-regression-models"><i class="fa fa-check"></i><b>2.5</b> Linear Regression Models</a></li>
<li class="chapter" data-level="2.6" data-path="linear-regression.html"><a href="linear-regression.html#using-lm"><i class="fa fa-check"></i><b>2.6</b> Using <code>lm()</code></a></li>
<li class="chapter" data-level="2.7" data-path="linear-regression.html"><a href="linear-regression.html#the-predict-function"><i class="fa fa-check"></i><b>2.7</b> The <code>predict()</code> Function</a></li>
<li class="chapter" data-level="2.8" data-path="linear-regression.html"><a href="linear-regression.html#data-splitting"><i class="fa fa-check"></i><b>2.8</b> Data Splitting</a></li>
<li class="chapter" data-level="2.9" data-path="linear-regression.html"><a href="linear-regression.html#regression-metrics"><i class="fa fa-check"></i><b>2.9</b> Regression Metrics</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="linear-regression.html"><a href="linear-regression.html#graphical-evaluation"><i class="fa fa-check"></i><b>2.9.1</b> Graphical Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="linear-regression.html"><a href="linear-regression.html#example-simple-simulated-data"><i class="fa fa-check"></i><b>2.10</b> Example: “Simple” Simulated Data</a></li>
<li class="chapter" data-level="2.11" data-path="linear-regression.html"><a href="linear-regression.html#example-diamonds-data"><i class="fa fa-check"></i><b>2.11</b> Example: Diamonds Data</a></li>
<li class="chapter" data-level="2.12" data-path="linear-regression.html"><a href="linear-regression.html#example-credit-card-data"><i class="fa fa-check"></i><b>2.12</b> Example: Credit Card Data</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html"><i class="fa fa-check"></i><b>3</b> Nonparametric Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html#r-setup-and-source-1"><i class="fa fa-check"></i><b>3.1</b> R Setup and Source</a></li>
<li class="chapter" data-level="3.2" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html#mathematical-setup-1"><i class="fa fa-check"></i><b>3.2</b> Mathematical Setup</a></li>
<li class="chapter" data-level="3.3" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>3.3</b> k-Nearest Neighbors</a></li>
<li class="chapter" data-level="3.4" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html#decision-trees"><i class="fa fa-check"></i><b>3.4</b> Decision Trees</a></li>
<li class="chapter" data-level="3.5" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html#example-credit-card-data-1"><i class="fa fa-check"></i><b>3.5</b> Example: Credit Card Data</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bias-variance-tradeoff.html"><a href="bias-variance-tradeoff.html"><i class="fa fa-check"></i><b>4</b> The Bias–Variance Tradeoff</a>
<ul>
<li class="chapter" data-level="4.1" data-path="bias-variance-tradeoff.html"><a href="bias-variance-tradeoff.html#r-setup-and-source-2"><i class="fa fa-check"></i><b>4.1</b> R Setup and Source</a></li>
<li class="chapter" data-level="4.2" data-path="bias-variance-tradeoff.html"><a href="bias-variance-tradeoff.html#the-regression-setup"><i class="fa fa-check"></i><b>4.2</b> The Regression Setup</a></li>
<li class="chapter" data-level="4.3" data-path="bias-variance-tradeoff.html"><a href="bias-variance-tradeoff.html#reducible-and-irreducible-error"><i class="fa fa-check"></i><b>4.3</b> Reducible and Irreducible Error</a></li>
<li class="chapter" data-level="4.4" data-path="bias-variance-tradeoff.html"><a href="bias-variance-tradeoff.html#bias-variance-decomposition"><i class="fa fa-check"></i><b>4.4</b> Bias-Variance Decomposition</a></li>
<li class="chapter" data-level="4.5" data-path="bias-variance-tradeoff.html"><a href="bias-variance-tradeoff.html#using-simulation-to-estimate-bias-and-variance"><i class="fa fa-check"></i><b>4.5</b> Using Simulation to Estimate Bias and Variance</a></li>
<li class="chapter" data-level="4.6" data-path="bias-variance-tradeoff.html"><a href="bias-variance-tradeoff.html#estimating-expected-prediction-error"><i class="fa fa-check"></i><b>4.6</b> Estimating Expected Prediction Error</a></li>
<li class="chapter" data-level="4.7" data-path="bias-variance-tradeoff.html"><a href="bias-variance-tradeoff.html#model-flexibility"><i class="fa fa-check"></i><b>4.7</b> Model Flexibility</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="bias-variance-tradeoff.html"><a href="bias-variance-tradeoff.html#linear-models"><i class="fa fa-check"></i><b>4.7.1</b> Linear Models</a></li>
<li class="chapter" data-level="4.7.2" data-path="bias-variance-tradeoff.html"><a href="bias-variance-tradeoff.html#k-nearest-neighbors-1"><i class="fa fa-check"></i><b>4.7.2</b> k-Nearest Neighbors</a></li>
<li class="chapter" data-level="4.7.3" data-path="bias-variance-tradeoff.html"><a href="bias-variance-tradeoff.html#decision-trees-1"><i class="fa fa-check"></i><b>4.7.3</b> Decision Trees</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="regression-overview.html"><a href="regression-overview.html"><i class="fa fa-check"></i><b>5</b> Regression Overview</a>
<ul>
<li class="chapter" data-level="5.1" data-path="regression-overview.html"><a href="regression-overview.html#the-goal"><i class="fa fa-check"></i><b>5.1</b> The Goal</a></li>
<li class="chapter" data-level="5.2" data-path="regression-overview.html"><a href="regression-overview.html#general-strategy"><i class="fa fa-check"></i><b>5.2</b> General Strategy</a></li>
<li class="chapter" data-level="5.3" data-path="regression-overview.html"><a href="regression-overview.html#aglorithms"><i class="fa fa-check"></i><b>5.3</b> Aglorithms</a></li>
<li class="chapter" data-level="5.4" data-path="regression-overview.html"><a href="regression-overview.html#model-flexibility-1"><i class="fa fa-check"></i><b>5.4</b> Model Flexibility</a></li>
<li class="chapter" data-level="5.5" data-path="regression-overview.html"><a href="regression-overview.html#overfitting"><i class="fa fa-check"></i><b>5.5</b> Overfitting</a></li>
<li class="chapter" data-level="5.6" data-path="regression-overview.html"><a href="regression-overview.html#bias-variance-tradeoff"><i class="fa fa-check"></i><b>5.6</b> Bias-Variance Tradeoff</a></li>
<li class="chapter" data-level="5.7" data-path="regression-overview.html"><a href="regression-overview.html#no-free-lunch"><i class="fa fa-check"></i><b>5.7</b> No Free Lunch</a></li>
<li class="chapter" data-level="5.8" data-path="regression-overview.html"><a href="regression-overview.html#curse-of-dimensionality"><i class="fa fa-check"></i><b>5.8</b> Curse of Dimensionality</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>6</b> Classification</a>
<ul>
<li class="chapter" data-level="6.1" data-path="classification.html"><a href="classification.html#r-setup-and-source-3"><i class="fa fa-check"></i><b>6.1</b> R Setup and Source</a></li>
<li class="chapter" data-level="6.2" data-path="classification.html"><a href="classification.html#data-setup"><i class="fa fa-check"></i><b>6.2</b> Data Setup</a></li>
<li class="chapter" data-level="6.3" data-path="classification.html"><a href="classification.html#mathematical-setup-2"><i class="fa fa-check"></i><b>6.3</b> Mathematical Setup</a></li>
<li class="chapter" data-level="6.4" data-path="classification.html"><a href="classification.html#example"><i class="fa fa-check"></i><b>6.4</b> Example</a></li>
<li class="chapter" data-level="6.5" data-path="classification.html"><a href="classification.html#bayes-classifier"><i class="fa fa-check"></i><b>6.5</b> Bayes Classifier</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="classification.html"><a href="classification.html#bayes-error-rate"><i class="fa fa-check"></i><b>6.5.1</b> Bayes Error Rate</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="classification.html"><a href="classification.html#building-a-classifier"><i class="fa fa-check"></i><b>6.6</b> Building a Classifier</a></li>
<li class="chapter" data-level="6.7" data-path="classification.html"><a href="classification.html#modeling"><i class="fa fa-check"></i><b>6.7</b> Modeling</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="classification.html"><a href="classification.html#linear-models-3"><i class="fa fa-check"></i><b>6.7.1</b> Linear Models</a></li>
<li class="chapter" data-level="6.7.2" data-path="classification.html"><a href="classification.html#k-nearest-neighbors-4"><i class="fa fa-check"></i><b>6.7.2</b> k-Nearest Neighbors</a></li>
<li class="chapter" data-level="6.7.3" data-path="classification.html"><a href="classification.html#decision-trees-3"><i class="fa fa-check"></i><b>6.7.3</b> Decision Trees</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="classification.html"><a href="classification.html#classification-metrics"><i class="fa fa-check"></i><b>6.8</b> Classification Metrics</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="classification.html"><a href="classification.html#misclassification"><i class="fa fa-check"></i><b>6.8.1</b> Misclassification</a></li>
<li class="chapter" data-level="6.8.2" data-path="classification.html"><a href="classification.html#accuracy"><i class="fa fa-check"></i><b>6.8.2</b> Accuracy</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="nonparametric-classification.html"><a href="nonparametric-classification.html"><i class="fa fa-check"></i><b>7</b> Nonparametric Classification</a>
<ul>
<li class="chapter" data-level="7.1" data-path="nonparametric-classification.html"><a href="nonparametric-classification.html#example-knn-on-simulated-data"><i class="fa fa-check"></i><b>7.1</b> Example: KNN on Simulated Data</a></li>
<li class="chapter" data-level="7.2" data-path="nonparametric-classification.html"><a href="nonparametric-classification.html#example-decision-tree-on-penguin-data"><i class="fa fa-check"></i><b>7.2</b> Example: Decision Tree on Penguin Data</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>8</b> Logistic Regression</a></li>
<li class="chapter" data-level="9" data-path="binary-classification.html"><a href="binary-classification.html"><i class="fa fa-check"></i><b>9</b> Binary Classification</a>
<ul>
<li class="chapter" data-level="9.1" data-path="binary-classification.html"><a href="binary-classification.html#r-setup-and-source-4"><i class="fa fa-check"></i><b>9.1</b> R Setup and Source</a></li>
<li class="chapter" data-level="9.2" data-path="binary-classification.html"><a href="binary-classification.html#breast-cancer-data"><i class="fa fa-check"></i><b>9.2</b> Breast Cancer Data</a></li>
<li class="chapter" data-level="9.3" data-path="binary-classification.html"><a href="binary-classification.html#confusion-matrix"><i class="fa fa-check"></i><b>9.3</b> Confusion Matrix</a></li>
<li class="chapter" data-level="9.4" data-path="binary-classification.html"><a href="binary-classification.html#binary-classification-metrics"><i class="fa fa-check"></i><b>9.4</b> Binary Classification Metrics</a></li>
<li class="chapter" data-level="9.5" data-path="binary-classification.html"><a href="binary-classification.html#probability-cutoff"><i class="fa fa-check"></i><b>9.5</b> Probability Cutoff</a></li>
<li class="chapter" data-level="9.6" data-path="binary-classification.html"><a href="binary-classification.html#r-packages-and-function"><i class="fa fa-check"></i><b>9.6</b> R Packages and Function</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="generative.html"><a href="generative.html"><i class="fa fa-check"></i><b>10</b> Generative Models</a>
<ul>
<li class="chapter" data-level="10.1" data-path="generative.html"><a href="generative.html#r-setup-and-source-5"><i class="fa fa-check"></i><b>10.1</b> R Setup and Source</a></li>
<li class="chapter" data-level="10.2" data-path="generative.html"><a href="generative.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>10.2</b> Linear Discriminant Analysis</a></li>
<li class="chapter" data-level="10.3" data-path="generative.html"><a href="generative.html#quadratic-discriminant-analysis"><i class="fa fa-check"></i><b>10.3</b> Quadratic Discriminant Analysis</a></li>
<li class="chapter" data-level="10.4" data-path="generative.html"><a href="generative.html#naive-bayes"><i class="fa fa-check"></i><b>10.4</b> Naive Bayes</a></li>
<li class="chapter" data-level="10.5" data-path="generative.html"><a href="generative.html#categorical-features"><i class="fa fa-check"></i><b>10.5</b> Categorical Features</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>11</b> Cross-Validation</a></li>
<li class="chapter" data-level="12" data-path="regularization.html"><a href="regularization.html"><i class="fa fa-check"></i><b>12</b> Regularization</a>
<ul>
<li class="chapter" data-level="12.1" data-path="regularization.html"><a href="regularization.html#ridge-regression"><i class="fa fa-check"></i><b>12.1</b> Ridge Regression</a></li>
<li class="chapter" data-level="12.2" data-path="regularization.html"><a href="regularization.html#lasso"><i class="fa fa-check"></i><b>12.2</b> Lasso</a></li>
<li class="chapter" data-level="12.3" data-path="regularization.html"><a href="regularization.html#broom"><i class="fa fa-check"></i><b>12.3</b> <code>broom</code></a></li>
<li class="chapter" data-level="12.4" data-path="regularization.html"><a href="regularization.html#simulated-data-p-n"><i class="fa fa-check"></i><b>12.4</b> Simulated Data, <span class="math inline">\(p &gt; n\)</span></a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ensemble-methods.html"><a href="ensemble-methods.html"><i class="fa fa-check"></i><b>13</b> Ensemble Methods</a>
<ul>
<li class="chapter" data-level="13.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#bagging"><i class="fa fa-check"></i><b>13.1</b> Bagging</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#reading"><i class="fa fa-check"></i><b>13.1.1</b> Reading</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#random-forest"><i class="fa fa-check"></i><b>13.2</b> Random Forest</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#reading-1"><i class="fa fa-check"></i><b>13.2.1</b> Reading</a></li>
<li class="chapter" data-level="13.2.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#video"><i class="fa fa-check"></i><b>13.2.2</b> Video</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ensemble-methods.html"><a href="ensemble-methods.html#boosting"><i class="fa fa-check"></i><b>13.3</b> Boosting</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="ensemble-methods.html"><a href="ensemble-methods.html#reading-2"><i class="fa fa-check"></i><b>13.3.1</b> Reading</a></li>
<li class="chapter" data-level="13.3.2" data-path="ensemble-methods.html"><a href="ensemble-methods.html#video-1"><i class="fa fa-check"></i><b>13.3.2</b> Video</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="supervised-overview.html"><a href="supervised-overview.html"><i class="fa fa-check"></i><b>14</b> Supervised Learning Overview II</a>
<ul>
<li class="chapter" data-level="14.1" data-path="supervised-overview.html"><a href="supervised-overview.html#classification-2"><i class="fa fa-check"></i><b>14.1</b> Classification</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="supervised-overview.html"><a href="supervised-overview.html#tuning"><i class="fa fa-check"></i><b>14.1.1</b> Tuning</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="supervised-overview.html"><a href="supervised-overview.html#regression-1"><i class="fa fa-check"></i><b>14.2</b> Regression</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="supervised-overview.html"><a href="supervised-overview.html#methods"><i class="fa fa-check"></i><b>14.2.1</b> Methods</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="supervised-overview.html"><a href="supervised-overview.html#external-links"><i class="fa fa-check"></i><b>14.3</b> External Links</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="additional-reading.html"><a href="additional-reading.html"><i class="fa fa-check"></i><b>A</b> Additional Reading</a>
<ul>
<li class="chapter" data-level="A.1" data-path="additional-reading.html"><a href="additional-reading.html#books"><i class="fa fa-check"></i><b>A.1</b> Books</a></li>
<li class="chapter" data-level="A.2" data-path="additional-reading.html"><a href="additional-reading.html#papers"><i class="fa fa-check"></i><b>A.2</b> Papers</a></li>
<li class="chapter" data-level="A.3" data-path="additional-reading.html"><a href="additional-reading.html#blog-posts"><i class="fa fa-check"></i><b>A.3</b> Blog Posts</a></li>
<li class="chapter" data-level="A.4" data-path="additional-reading.html"><a href="additional-reading.html#miscellaneous"><i class="fa fa-check"></i><b>A.4</b> Miscellaneous</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="computing.html"><a href="computing.html"><i class="fa fa-check"></i><b>B</b> Computing</a>
<ul>
<li class="chapter" data-level="B.1" data-path="computing.html"><a href="computing.html#reading-3"><i class="fa fa-check"></i><b>B.1</b> Reading</a></li>
<li class="chapter" data-level="B.2" data-path="computing.html"><a href="computing.html#additional-resources"><i class="fa fa-check"></i><b>B.2</b> Additional Resources</a>
<ul>
<li class="chapter" data-level="B.2.1" data-path="computing.html"><a href="computing.html#r"><i class="fa fa-check"></i><b>B.2.1</b> R</a></li>
<li class="chapter" data-level="B.2.2" data-path="computing.html"><a href="computing.html#rstudio"><i class="fa fa-check"></i><b>B.2.2</b> RStudio</a></li>
<li class="chapter" data-level="B.2.3" data-path="computing.html"><a href="computing.html#r-markdown"><i class="fa fa-check"></i><b>B.2.3</b> R Markdown</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="computing.html"><a href="computing.html#stat-432-idioms"><i class="fa fa-check"></i><b>B.3</b> STAT 432 Idioms</a>
<ul>
<li class="chapter" data-level="B.3.1" data-path="computing.html"><a href="computing.html#dont-restore-old-workspaces"><i class="fa fa-check"></i><b>B.3.1</b> Don’t Restore Old Workspaces</a></li>
<li class="chapter" data-level="B.3.2" data-path="computing.html"><a href="computing.html#r-versions"><i class="fa fa-check"></i><b>B.3.2</b> R Versions</a></li>
<li class="chapter" data-level="B.3.3" data-path="computing.html"><a href="computing.html#packages-1"><i class="fa fa-check"></i><b>B.3.3</b> Packages</a></li>
<li class="chapter" data-level="B.3.4" data-path="computing.html"><a href="computing.html#code-style"><i class="fa fa-check"></i><b>B.3.4</b> Code Style</a></li>
<li class="chapter" data-level="B.3.5" data-path="computing.html"><a href="computing.html#reference-style"><i class="fa fa-check"></i><b>B.3.5</b> Reference Style</a></li>
<li class="chapter" data-level="B.3.6" data-path="computing.html"><a href="computing.html#stat-432-r-style-overrides"><i class="fa fa-check"></i><b>B.3.6</b> STAT 432 R Style Overrides</a></li>
<li class="chapter" data-level="B.3.7" data-path="computing.html"><a href="computing.html#stat-432-r-markdown-style"><i class="fa fa-check"></i><b>B.3.7</b> STAT 432 R Markdown Style</a></li>
<li class="chapter" data-level="B.3.8" data-path="computing.html"><a href="computing.html#style-heuristics"><i class="fa fa-check"></i><b>B.3.8</b> Style Heuristics</a></li>
<li class="chapter" data-level="B.3.9" data-path="computing.html"><a href="computing.html#objects-and-functions"><i class="fa fa-check"></i><b>B.3.9</b> Objects and Functions</a></li>
<li class="chapter" data-level="B.3.10" data-path="computing.html"><a href="computing.html#print-versus-return"><i class="fa fa-check"></i><b>B.3.10</b> Print versus Return</a></li>
<li class="chapter" data-level="B.3.11" data-path="computing.html"><a href="computing.html#help"><i class="fa fa-check"></i><b>B.3.11</b> Help</a></li>
<li class="chapter" data-level="B.3.12" data-path="computing.html"><a href="computing.html#keyboard-shortcuts"><i class="fa fa-check"></i><b>B.3.12</b> Keyboard Shortcuts</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>C</b> Probability</a>
<ul>
<li class="chapter" data-level="C.1" data-path="probability.html"><a href="probability.html#reading-4"><i class="fa fa-check"></i><b>C.1</b> Reading</a></li>
<li class="chapter" data-level="C.2" data-path="probability.html"><a href="probability.html#probability-models"><i class="fa fa-check"></i><b>C.2</b> Probability Models</a></li>
<li class="chapter" data-level="C.3" data-path="probability.html"><a href="probability.html#probability-axioms"><i class="fa fa-check"></i><b>C.3</b> Probability Axioms</a></li>
<li class="chapter" data-level="C.4" data-path="probability.html"><a href="probability.html#probability-rules"><i class="fa fa-check"></i><b>C.4</b> Probability Rules</a></li>
<li class="chapter" data-level="C.5" data-path="probability.html"><a href="probability.html#random-variables"><i class="fa fa-check"></i><b>C.5</b> Random Variables</a>
<ul>
<li class="chapter" data-level="C.5.1" data-path="probability.html"><a href="probability.html#distributions"><i class="fa fa-check"></i><b>C.5.1</b> Distributions</a></li>
<li class="chapter" data-level="C.5.2" data-path="probability.html"><a href="probability.html#discrete-random-variables"><i class="fa fa-check"></i><b>C.5.2</b> Discrete Random Variables</a></li>
<li class="chapter" data-level="C.5.3" data-path="probability.html"><a href="probability.html#continuous-random-variables"><i class="fa fa-check"></i><b>C.5.3</b> Continuous Random Variables</a></li>
<li class="chapter" data-level="C.5.4" data-path="probability.html"><a href="probability.html#distributions-in-r"><i class="fa fa-check"></i><b>C.5.4</b> Distributions in R</a></li>
<li class="chapter" data-level="C.5.5" data-path="probability.html"><a href="probability.html#several-random-variables"><i class="fa fa-check"></i><b>C.5.5</b> Several Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="C.6" data-path="probability.html"><a href="probability.html#expectations"><i class="fa fa-check"></i><b>C.6</b> Expectations</a></li>
<li class="chapter" data-level="C.7" data-path="probability.html"><a href="probability.html#likelihood"><i class="fa fa-check"></i><b>C.7</b> Likelihood</a></li>
<li class="chapter" data-level="C.8" data-path="probability.html"><a href="probability.html#additional-references"><i class="fa fa-check"></i><b>C.8</b> Additional References</a>
<ul>
<li class="chapter" data-level="C.8.1" data-path="probability.html"><a href="probability.html#videos"><i class="fa fa-check"></i><b>C.8.1</b> Videos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="statistics.html"><a href="statistics.html"><i class="fa fa-check"></i><b>D</b> Statistics</a>
<ul>
<li class="chapter" data-level="D.1" data-path="statistics.html"><a href="statistics.html#reading-5"><i class="fa fa-check"></i><b>D.1</b> Reading</a></li>
<li class="chapter" data-level="D.2" data-path="statistics.html"><a href="statistics.html#statistics-1"><i class="fa fa-check"></i><b>D.2</b> Statistics</a></li>
<li class="chapter" data-level="D.3" data-path="statistics.html"><a href="statistics.html#estimators"><i class="fa fa-check"></i><b>D.3</b> Estimators</a>
<ul>
<li class="chapter" data-level="D.3.1" data-path="statistics.html"><a href="statistics.html#properties"><i class="fa fa-check"></i><b>D.3.1</b> Properties</a></li>
<li class="chapter" data-level="D.3.2" data-path="statistics.html"><a href="statistics.html#example-mse-of-an-estimator"><i class="fa fa-check"></i><b>D.3.2</b> Example: MSE of an Estimator</a></li>
<li class="chapter" data-level="D.3.3" data-path="statistics.html"><a href="statistics.html#estimation-methods"><i class="fa fa-check"></i><b>D.3.3</b> Estimation Methods</a></li>
<li class="chapter" data-level="D.3.4" data-path="statistics.html"><a href="statistics.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>D.3.4</b> Maximum Likelihood Estimation</a></li>
<li class="chapter" data-level="D.3.5" data-path="statistics.html"><a href="statistics.html#method-of-moments"><i class="fa fa-check"></i><b>D.3.5</b> Method of Moments</a></li>
<li class="chapter" data-level="D.3.6" data-path="statistics.html"><a href="statistics.html#empirical-distribution-function"><i class="fa fa-check"></i><b>D.3.6</b> Empirical Distribution Function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://daviddalpiaz.org" target="blank">&copy; 2020 David Dalpiaz</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Basics of Statistical Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="generative-models" class="section level1" number="10">
<h1><span class="header-section-number">Chapter 10</span> Generative Models</h1>
<p>In this chapter, we continue our discussion of classification methods. We introduce three new methods, each a <strong>generative</strong> method.</p>
<p>Specifically, we will discuss:</p>
<ul>
<li>How <strong>generative</strong> methods are different than <strong>discriminative</strong> methods like logistic regression.</li>
<li>How generative methods model the joint probability, <span class="math inline">\(p(\boldsymbol{x}, y)\)</span>, often by assuming some distribution for the conditional distribution of <span class="math inline">\(\boldsymbol{X}\)</span> given <span class="math inline">\(Y\)</span>, <span class="math inline">\(f(\boldsymbol{x} \mid y)\)</span>.</li>
<li>How to use Bayes theorem to classify according to <span class="math inline">\(p(y \mid \boldsymbol{x})\)</span> as compared to discriminative methods such as logistic regression directly model this conditional directly.</li>
</ul>
<p>Two potential additional readigns:</p>
<ul>
<li><a href="https://papers.nips.cc/paper/2020-on-discriminative-vs-generative-classifiers-a-comparison-of-logistic-regression-and-naive-bayes.pdf">Ng and Jordan, 2002</a>.</li>
<li><a href="https://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf">ISL Chapter 4, Sections 4</a></li>
</ul>
<p>This chapter is currently <strong>under construction</strong>. While it is being developed, the following links to the STAT 432 course notes.</p>
<ul>
<li><a href="files/generative.pdf"><strong>Notes:</strong> Generative Models</a></li>
</ul>
<hr />
<div id="r-setup-and-source-5" class="section level2" number="10.1">
<h2><span class="header-section-number">10.1</span> R Setup and Source</h2>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="generative.html#cb283-1"></a><span class="kw">library</span>(palmerpenguins) <span class="co"># access to data</span></span>
<span id="cb283-2"><a href="generative.html#cb283-2"></a><span class="kw">library</span>(tibble)         <span class="co"># data frame printing</span></span>
<span id="cb283-3"><a href="generative.html#cb283-3"></a></span>
<span id="cb283-4"><a href="generative.html#cb283-4"></a><span class="kw">library</span>(MASS)           <span class="co"># fitting lda and qda</span></span>
<span id="cb283-5"><a href="generative.html#cb283-5"></a><span class="kw">library</span>(klaR)           <span class="co"># fitting naive bayes</span></span>
<span id="cb283-6"><a href="generative.html#cb283-6"></a></span>
<span id="cb283-7"><a href="generative.html#cb283-7"></a><span class="kw">library</span>(knitr)          <span class="co"># creating tables</span></span>
<span id="cb283-8"><a href="generative.html#cb283-8"></a><span class="kw">library</span>(kableExtra)     <span class="co"># styling tables</span></span></code></pre></div>
<p>Recall that the <a href="index.html">Welcome</a> chapter contains directions for installing all necessary packages for following along with the text. The R Markdown source is provided as some code, mostly for creating plots, has been suppressed from the rendered document that you are currently reading.</p>
<ul>
<li><strong>R Markdown Source:</strong> <a href="generative.Rmd"><code>generative.Rmd</code></a></li>
</ul>
<hr />
<p>Each of the methods in this chapter will use Bayes theorem to build a classifier.</p>
<p><span class="math display">\[
p_k(\boldsymbol{x}) = P(Y = k \mid \boldsymbol{X} = \boldsymbol{x}) = \frac{\pi_k \cdot f_k(\boldsymbol{x})}{\sum_{g = 1}^{G} \pi_g \cdot f_g(\boldsymbol{x})}
\]</span></p>
<p>We call <span class="math inline">\(p_k(\boldsymbol{x})\)</span> the <strong>posterior</strong> probability, which we will estimate then use to create classifications. The <span class="math inline">\(\pi_g\)</span> are called the <strong>prior</strong> probabilities for each possible classes <span class="math inline">\(g\)</span>. That is, <span class="math inline">\(\pi_g = P(Y = g)\)</span>, unconditioned on <span class="math inline">\(\boldsymbol X\)</span>. (Here, there are <span class="math inline">\(G\)</span> possible classes, denoted <span class="math inline">\(1, 2, \ldots G\)</span>. We use <span class="math inline">\(k\)</span> to refer to a particular class.) The <span class="math inline">\(f_g(x)\)</span> are called the <strong>likelihoods</strong>, which are indexed by <span class="math inline">\(g\)</span> to denote that they are conditional on the classes. The denominator is often referred to as a <strong>normalizing constant</strong>.</p>
<p>The methods will differ by placing different modeling assumptions on the likelihoods, <span class="math inline">\(f_g(\boldsymbol x)\)</span>. For each method, the priors could be learned from data or pre-specified.</p>
<p>For each method, classifications are made to the class with the highest estimated posterior probability, which is equivalent to the class with the largest</p>
<p><span class="math display">\[
\log(\hat{\pi}_k \cdot \hat{f}_k(\boldsymbol{x})).
\]</span></p>
<p>By substituting the corresponding likelihoods, simplifying, and eliminating unnecessary terms, we could derive the discriminant function for each.</p>
<p>To illustrate these new methods, we return to the Palmer penguins data, which you may remember has three classes. After a train-test and estimation-validation split, we create a number of plots to refresh our memory. Note that these splits are a bit odd in terms of proprotions. This is for illustrative purposes only.</p>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb284-1"><a href="generative.html#cb284-1"></a>peng =<span class="st"> </span><span class="kw">na.omit</span>(penguins)</span></code></pre></div>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="generative.html#cb285-1"></a><span class="co"># set seed</span></span>
<span id="cb285-2"><a href="generative.html#cb285-2"></a><span class="kw">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb285-3"><a href="generative.html#cb285-3"></a></span>
<span id="cb285-4"><a href="generative.html#cb285-4"></a><span class="co"># train-test split</span></span>
<span id="cb285-5"><a href="generative.html#cb285-5"></a>trn_idx =<span class="st"> </span><span class="kw">sample</span>(<span class="kw">nrow</span>(peng), <span class="dt">size =</span> <span class="kw">trunc</span>(<span class="fl">0.50</span> <span class="op">*</span><span class="st"> </span><span class="kw">nrow</span>(peng)))</span>
<span id="cb285-6"><a href="generative.html#cb285-6"></a>peng_trn =<span class="st"> </span>peng[trn_idx, ]</span>
<span id="cb285-7"><a href="generative.html#cb285-7"></a>peng_tst =<span class="st"> </span>peng[<span class="op">-</span>trn_idx, ]</span>
<span id="cb285-8"><a href="generative.html#cb285-8"></a></span>
<span id="cb285-9"><a href="generative.html#cb285-9"></a><span class="co"># train-test split</span></span>
<span id="cb285-10"><a href="generative.html#cb285-10"></a>est_idx =<span class="st"> </span><span class="kw">sample</span>(<span class="kw">nrow</span>(peng_trn), <span class="dt">size =</span> <span class="kw">trunc</span>(<span class="fl">0.50</span> <span class="op">*</span><span class="st"> </span><span class="kw">nrow</span>(peng_trn)))</span>
<span id="cb285-11"><a href="generative.html#cb285-11"></a>peng_est =<span class="st"> </span>peng_trn[est_idx, ]</span>
<span id="cb285-12"><a href="generative.html#cb285-12"></a>peng_val =<span class="st"> </span>peng_trn[<span class="op">-</span>est_idx, ]</span></code></pre></div>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="generative.html#cb286-1"></a>caret<span class="op">::</span><span class="kw">featurePlot</span>(</span>
<span id="cb286-2"><a href="generative.html#cb286-2"></a>  <span class="dt">x =</span> peng_trn[, <span class="kw">c</span>(<span class="st">&quot;bill_length_mm&quot;</span>,</span>
<span id="cb286-3"><a href="generative.html#cb286-3"></a>                   <span class="st">&quot;bill_depth_mm&quot;</span>,</span>
<span id="cb286-4"><a href="generative.html#cb286-4"></a>                   <span class="st">&quot;flipper_length_mm&quot;</span>,</span>
<span id="cb286-5"><a href="generative.html#cb286-5"></a>                   <span class="st">&quot;body_mass_g&quot;</span>)],</span>
<span id="cb286-6"><a href="generative.html#cb286-6"></a>  <span class="dt">y =</span> peng_trn<span class="op">$</span>species,</span>
<span id="cb286-7"><a href="generative.html#cb286-7"></a>  <span class="dt">plot =</span> <span class="st">&quot;density&quot;</span>,</span>
<span id="cb286-8"><a href="generative.html#cb286-8"></a>  <span class="dt">scales =</span> <span class="kw">list</span>(</span>
<span id="cb286-9"><a href="generative.html#cb286-9"></a>    <span class="dt">x =</span> <span class="kw">list</span>(<span class="dt">relation =</span> <span class="st">&quot;free&quot;</span>),</span>
<span id="cb286-10"><a href="generative.html#cb286-10"></a>    <span class="dt">y =</span> <span class="kw">list</span>(<span class="dt">relation =</span> <span class="st">&quot;free&quot;</span>)</span>
<span id="cb286-11"><a href="generative.html#cb286-11"></a>  ),</span>
<span id="cb286-12"><a href="generative.html#cb286-12"></a>  <span class="dt">adjust =</span> <span class="fl">1.5</span>,</span>
<span id="cb286-13"><a href="generative.html#cb286-13"></a>  <span class="dt">pch =</span> <span class="st">&quot;|&quot;</span>,</span>
<span id="cb286-14"><a href="generative.html#cb286-14"></a>  <span class="dt">layout =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>),</span>
<span id="cb286-15"><a href="generative.html#cb286-15"></a>  <span class="dt">auto.key =</span> <span class="kw">list</span>(<span class="dt">columns =</span> <span class="dv">3</span>)</span>
<span id="cb286-16"><a href="generative.html#cb286-16"></a>)</span></code></pre></div>
<p><img src="generative_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="generative.html#cb287-1"></a>caret<span class="op">::</span><span class="kw">featurePlot</span>(</span>
<span id="cb287-2"><a href="generative.html#cb287-2"></a>  <span class="dt">x =</span> peng_trn[, <span class="kw">c</span>(<span class="st">&quot;bill_length_mm&quot;</span>,</span>
<span id="cb287-3"><a href="generative.html#cb287-3"></a>                   <span class="st">&quot;bill_depth_mm&quot;</span>,</span>
<span id="cb287-4"><a href="generative.html#cb287-4"></a>                   <span class="st">&quot;flipper_length_mm&quot;</span>,</span>
<span id="cb287-5"><a href="generative.html#cb287-5"></a>                   <span class="st">&quot;body_mass_g&quot;</span>)],</span>
<span id="cb287-6"><a href="generative.html#cb287-6"></a>  <span class="dt">y =</span> peng_trn<span class="op">$</span>species,</span>
<span id="cb287-7"><a href="generative.html#cb287-7"></a>  <span class="dt">plot =</span> <span class="st">&quot;ellipse&quot;</span>,</span>
<span id="cb287-8"><a href="generative.html#cb287-8"></a>  <span class="dt">auto.key =</span> <span class="kw">list</span>(<span class="dt">columns =</span> <span class="dv">3</span>)</span>
<span id="cb287-9"><a href="generative.html#cb287-9"></a>)</span></code></pre></div>
<p><img src="generative_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="generative.html#cb288-1"></a>caret<span class="op">::</span><span class="kw">featurePlot</span>(</span>
<span id="cb288-2"><a href="generative.html#cb288-2"></a>  <span class="dt">x =</span> peng_trn[, <span class="kw">c</span>(<span class="st">&quot;bill_length_mm&quot;</span>,</span>
<span id="cb288-3"><a href="generative.html#cb288-3"></a>                   <span class="st">&quot;bill_depth_mm&quot;</span>,</span>
<span id="cb288-4"><a href="generative.html#cb288-4"></a>                   <span class="st">&quot;flipper_length_mm&quot;</span>,</span>
<span id="cb288-5"><a href="generative.html#cb288-5"></a>                   <span class="st">&quot;body_mass_g&quot;</span>)],</span>
<span id="cb288-6"><a href="generative.html#cb288-6"></a>  <span class="dt">y =</span> peng_trn<span class="op">$</span>species,</span>
<span id="cb288-7"><a href="generative.html#cb288-7"></a>  <span class="dt">plot =</span> <span class="st">&quot;box&quot;</span>,</span>
<span id="cb288-8"><a href="generative.html#cb288-8"></a>  <span class="dt">scales =</span> <span class="kw">list</span>(<span class="dt">y =</span> <span class="kw">list</span>(<span class="dt">relation =</span> <span class="st">&quot;free&quot;</span>),</span>
<span id="cb288-9"><a href="generative.html#cb288-9"></a>                <span class="dt">x =</span> <span class="kw">list</span>(<span class="dt">rot =</span> <span class="dv">90</span>)),</span>
<span id="cb288-10"><a href="generative.html#cb288-10"></a>  <span class="dt">layout =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">1</span>)</span>
<span id="cb288-11"><a href="generative.html#cb288-11"></a>)</span></code></pre></div>
<p><img src="generative_files/figure-html/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Especially based on the pairs plot, we see that it should not be too difficult to find a good classifier. Because it is so easy will we create models using only <code>bill_length_mm</code> and <code>flipper_length_mm</code> so that they will make some errors that we can discuss.</p>
<p>Notice that we use <code>caret::featurePlot</code> to access the <code>featurePlot()</code> function without loading the entire <code>caret</code> package.</p>
<hr />
</div>
<div id="linear-discriminant-analysis" class="section level2" number="10.2">
<h2><span class="header-section-number">10.2</span> Linear Discriminant Analysis</h2>
<p>Linear Discriminant Analysis, <strong>LDA</strong>, assumes that the features are multivariate normal conditioned on the classes.</p>
<p><span class="math display">\[
\boldsymbol{X} \mid Y = k \sim N(\boldsymbol{\mu}_k, \boldsymbol\Sigma)
\]</span></p>
<p><span class="math display">\[
f_k(\boldsymbol{x}) = \frac{1}{(2\pi)^{p/2}|\boldsymbol\Sigma|^{1/2}}\exp\left[-\frac{1}{2}(\boldsymbol x - \boldsymbol\mu_k)^{\prime}\boldsymbol\Sigma^{-1}(\boldsymbol x - \boldsymbol\mu_k)\right]
\]</span></p>
<p>Notice that <span class="math inline">\(\boldsymbol\Sigma\)</span> does <strong>not</strong> depend on <span class="math inline">\(k\)</span>, that is, we are assuming the same <span class="math inline">\(\Sigma\)</span> for each class. We then use information from all the classes to estimate <span class="math inline">\(\boldsymbol\Sigma\)</span>.</p>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="generative.html#cb289-1"></a>peng_lda =<span class="st"> </span><span class="kw">lda</span>(species <span class="op">~</span><span class="st"> </span>bill_length_mm <span class="op">+</span><span class="st"> </span>flipper_length_mm, <span class="dt">data =</span> peng_est)</span>
<span id="cb289-2"><a href="generative.html#cb289-2"></a>peng_lda</span></code></pre></div>
<pre><code>## Call:
## lda(species ~ bill_length_mm + flipper_length_mm, data = peng_est)
## 
## Prior probabilities of groups:
##    Adelie Chinstrap    Gentoo 
## 0.4457831 0.1566265 0.3975904 
## 
## Group means:
##           bill_length_mm flipper_length_mm
## Adelie          39.08108          190.0000
## Chinstrap       48.32308          194.9231
## Gentoo          46.75152          215.9697
## 
## Coefficients of linear discriminants:
##                          LD1        LD2
## bill_length_mm    0.03300363 -0.4289076
## flipper_length_mm 0.18519532  0.1087346
## 
## Proportion of trace:
##    LD1    LD2 
## 0.7984 0.2016</code></pre>
<p>Here we see the estimated <span class="math inline">\(\hat{\pi}_k\)</span> and <span class="math inline">\(\hat{\boldsymbol\mu}_k\)</span> for each class.</p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="generative.html#cb291-1"></a><span class="kw">is.list</span>(<span class="kw">predict</span>(peng_lda, peng_est))</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="generative.html#cb293-1"></a><span class="kw">names</span>(<span class="kw">predict</span>(peng_lda, peng_est))</span></code></pre></div>
<pre><code>## [1] &quot;class&quot;     &quot;posterior&quot; &quot;x&quot;</code></pre>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="generative.html#cb295-1"></a><span class="kw">head</span>(<span class="kw">predict</span>(peng_lda, peng_est)<span class="op">$</span>class, <span class="dt">n =</span> <span class="dv">10</span>)</span></code></pre></div>
<pre><code>##  [1] Gentoo    Adelie    Adelie    Adelie    Adelie    Gentoo    Chinstrap
##  [8] Adelie    Adelie    Gentoo   
## Levels: Adelie Chinstrap Gentoo</code></pre>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="generative.html#cb297-1"></a><span class="kw">head</span>(<span class="kw">predict</span>(peng_lda, peng_est)<span class="op">$</span>posterior, <span class="dt">n =</span> <span class="dv">10</span>)</span></code></pre></div>
<pre><code>##          Adelie    Chinstrap       Gentoo
## 1  3.106976e-03 6.281033e-06 9.968867e-01
## 2  9.988138e-01 1.185724e-03 4.300706e-07
## 3  9.998919e-01 1.066133e-04 1.517790e-06
## 4  9.828029e-01 1.719710e-02 5.064431e-10
## 5  8.222950e-01 2.184971e-03 1.755200e-01
## 6  7.514839e-05 7.801291e-06 9.999171e-01
## 7  3.723269e-02 9.627490e-01 1.830132e-05
## 8  9.966890e-01 8.415898e-06 3.302621e-03
## 9  9.999794e-01 2.016388e-05 4.025448e-07
## 10 3.830348e-09 1.184353e-05 9.999882e-01</code></pre>
<p>As we should come to expect, the <code>predict()</code> function operates in a new way when called on an <code>lda</code> object. By default, it returns an entire list. Within that list <code>class</code> stores the classifications and <code>posterior</code> contains the estimated probability for each class.</p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="generative.html#cb299-1"></a>peng_lda_est_pred =<span class="st"> </span><span class="kw">predict</span>(peng_lda, peng_est)<span class="op">$</span>class</span>
<span id="cb299-2"><a href="generative.html#cb299-2"></a>peng_lda_val_pred =<span class="st"> </span><span class="kw">predict</span>(peng_lda, peng_val)<span class="op">$</span>class</span></code></pre></div>
<p>We store the predictions made on the estimation and validatino sets.</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="generative.html#cb300-1"></a>calc_misclass =<span class="st"> </span><span class="cf">function</span>(actual, predicted) {</span>
<span id="cb300-2"><a href="generative.html#cb300-2"></a>  <span class="kw">mean</span>(actual <span class="op">!=</span><span class="st"> </span>predicted)</span>
<span id="cb300-3"><a href="generative.html#cb300-3"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="generative.html#cb301-1"></a><span class="kw">calc_misclass</span>(<span class="dt">predicted =</span> peng_lda_est_pred, <span class="dt">actual =</span> peng_est<span class="op">$</span>species)</span></code></pre></div>
<pre><code>## [1] 0.01204819</code></pre>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="generative.html#cb303-1"></a><span class="kw">calc_misclass</span>(<span class="dt">predicted =</span> peng_lda_val_pred, <span class="dt">actual =</span> peng_val<span class="op">$</span>species)</span></code></pre></div>
<pre><code>## [1] 0.08433735</code></pre>
<p>As expected, LDA performs well on both the estimation and validation data.</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="generative.html#cb305-1"></a><span class="kw">table</span>(<span class="dt">predicted =</span> peng_lda_val_pred, <span class="dt">actual =</span> peng_val<span class="op">$</span>species)</span></code></pre></div>
<pre><code>##            actual
## predicted   Adelie Chinstrap Gentoo
##   Adelie        31         2      0
##   Chinstrap      1        16      0
##   Gentoo         2         2     29</code></pre>
<p>Looking at the validation set, we see that we are perfectly within the Gentoos.</p>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="generative.html#cb307-1"></a>peng_lda_flat =<span class="st"> </span><span class="kw">lda</span>(species <span class="op">~</span><span class="st"> </span>bill_length_mm <span class="op">+</span><span class="st"> </span>flipper_length_mm, </span>
<span id="cb307-2"><a href="generative.html#cb307-2"></a>                    <span class="dt">data =</span> peng_est, <span class="dt">prior =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>) <span class="op">/</span><span class="st"> </span><span class="dv">3</span>)</span>
<span id="cb307-3"><a href="generative.html#cb307-3"></a>peng_lda_flat</span></code></pre></div>
<pre><code>## Call:
## lda(species ~ bill_length_mm + flipper_length_mm, data = peng_est, 
##     prior = c(1, 1, 1)/3)
## 
## Prior probabilities of groups:
##    Adelie Chinstrap    Gentoo 
## 0.3333333 0.3333333 0.3333333 
## 
## Group means:
##           bill_length_mm flipper_length_mm
## Adelie          39.08108          190.0000
## Chinstrap       48.32308          194.9231
## Gentoo          46.75152          215.9697
## 
## Coefficients of linear discriminants:
##                           LD1         LD2
## bill_length_mm    -0.05945813 -0.42604662
## flipper_length_mm  0.20416030  0.06662646
## 
## Proportion of trace:
##    LD1    LD2 
## 0.6858 0.3142</code></pre>
<p>Instead of learning (estimating) the proportion of the three species from the data, we could instead specify them ourselves. Here we choose a uniform distributions over the possible species. We would call this a “flat” prior.</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="generative.html#cb309-1"></a>peng_lda_flat_est_pred =<span class="st"> </span><span class="kw">predict</span>(peng_lda_flat, peng_est)<span class="op">$</span>class</span>
<span id="cb309-2"><a href="generative.html#cb309-2"></a>peng_lda_flat_val_pred =<span class="st"> </span><span class="kw">predict</span>(peng_lda_flat, peng_val)<span class="op">$</span>class</span></code></pre></div>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="generative.html#cb310-1"></a><span class="kw">calc_misclass</span>(<span class="dt">predicted =</span> peng_lda_flat_est_pred, <span class="dt">actual =</span> peng_est<span class="op">$</span>species)</span></code></pre></div>
<pre><code>## [1] 0.01204819</code></pre>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="generative.html#cb312-1"></a><span class="kw">calc_misclass</span>(<span class="dt">predicted =</span> peng_lda_flat_val_pred, <span class="dt">actual =</span> peng_val<span class="op">$</span>species)</span></code></pre></div>
<pre><code>## [1] 0.07228916</code></pre>
<p>This actually gives a better test accuracy! In practice, this could be useful if you have prior knowledge about the future proportions of the response variable.</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="generative.html#cb314-1"></a><span class="kw">table</span>(peng_val<span class="op">$</span>species) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(peng_val<span class="op">$</span>species)</span></code></pre></div>
<pre><code>## 
##    Adelie Chinstrap    Gentoo 
## 0.4096386 0.2409639 0.3493976</code></pre>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="generative.html#cb316-1"></a>peng_lda<span class="op">$</span>prior</span></code></pre></div>
<pre><code>##    Adelie Chinstrap    Gentoo 
## 0.4457831 0.1566265 0.3975904</code></pre>
<p>Looking at the above, we see this makes sense. In the validation data, the proportions of the classes are closer to flat. However, you should not use this information to choose your prior in practice. That would be cheating. If you have other information that suggests you should try this, then go right ahead.</p>
<hr />
</div>
<div id="quadratic-discriminant-analysis" class="section level2" number="10.3">
<h2><span class="header-section-number">10.3</span> Quadratic Discriminant Analysis</h2>
<p>Quadratic Discriminant Analysis, <strong>QDA</strong>, also assumes that the features are multivariate normal conditioned on the classes.</p>
<p><span class="math display">\[
\boldsymbol X \mid Y = k \sim N(\boldsymbol\mu_k, \boldsymbol\Sigma_k)
\]</span></p>
<p><span class="math display">\[
f_k(\boldsymbol x) = \frac{1}{(2\pi)^{p/2}|\boldsymbol\Sigma_k|^{1/2}}\exp\left[-\frac{1}{2}(\boldsymbol x - \boldsymbol\mu_k)^{\prime}\boldsymbol\Sigma_{k}^{-1}(\boldsymbol x - \boldsymbol\mu_k)\right]
\]</span></p>
<p>Notice that now <span class="math inline">\(\boldsymbol\Sigma_k\)</span> <strong>does</strong> depend on <span class="math inline">\(k\)</span>, that is, we are allowing a different <span class="math inline">\(\boldsymbol\Sigma_k\)</span> for each class. We only use information from class <span class="math inline">\(k\)</span> to estimate <span class="math inline">\(\Sigma_k\)</span>.</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="generative.html#cb318-1"></a>peng_qda =<span class="st"> </span><span class="kw">qda</span>(species <span class="op">~</span><span class="st"> </span>bill_length_mm <span class="op">+</span><span class="st"> </span>flipper_length_mm, <span class="dt">data =</span> peng_est)</span>
<span id="cb318-2"><a href="generative.html#cb318-2"></a>peng_qda</span></code></pre></div>
<pre><code>## Call:
## qda(species ~ bill_length_mm + flipper_length_mm, data = peng_est)
## 
## Prior probabilities of groups:
##    Adelie Chinstrap    Gentoo 
## 0.4457831 0.1566265 0.3975904 
## 
## Group means:
##           bill_length_mm flipper_length_mm
## Adelie          39.08108          190.0000
## Chinstrap       48.32308          194.9231
## Gentoo          46.75152          215.9697</code></pre>
<p>Here the output is similar to LDA, again giving the estimated <span class="math inline">\(\hat{\pi}_k\)</span> and <span class="math inline">\(\hat{\boldsymbol\mu}_k\)</span> for each class. Like <code>lda()</code>, the <code>qda()</code> function is found in the <code>MASS</code> package.</p>
<p>Consider trying to fit QDA again, but this time with a <em>very small</em> estimation set. This will cause an error because there are not enough observations within each class to estimate the large number of parameters in the <span class="math inline">\(\boldsymbol\Sigma_k\)</span> matrices. This is less of a problem with LDA, since all observations, no matter the class, are being use to estimate the shared <span class="math inline">\(\boldsymbol\Sigma\)</span> matrix.</p>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="generative.html#cb320-1"></a>peng_qda_est_pred =<span class="st"> </span><span class="kw">predict</span>(peng_qda, peng_est)<span class="op">$</span>class</span>
<span id="cb320-2"><a href="generative.html#cb320-2"></a>peng_qda_val_pred =<span class="st"> </span><span class="kw">predict</span>(peng_qda, peng_val)<span class="op">$</span>class</span></code></pre></div>
<p>The <code>predict()</code> function operates the same as the <code>predict()</code> function for LDA.</p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="generative.html#cb321-1"></a><span class="kw">calc_misclass</span>(<span class="dt">predicted =</span> peng_qda_est_pred, <span class="dt">actual =</span> peng_est<span class="op">$</span>species)</span></code></pre></div>
<pre><code>## [1] 0.01204819</code></pre>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="generative.html#cb323-1"></a><span class="kw">calc_misclass</span>(<span class="dt">predicted =</span> peng_qda_val_pred, <span class="dt">actual =</span> peng_val<span class="op">$</span>species)</span></code></pre></div>
<pre><code>## [1] 0.09638554</code></pre>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="generative.html#cb325-1"></a><span class="kw">table</span>(<span class="dt">predicted =</span> peng_qda_val_pred, <span class="dt">actual =</span> peng_val<span class="op">$</span>species)</span></code></pre></div>
<pre><code>##            actual
## predicted   Adelie Chinstrap Gentoo
##   Adelie        30         1      0
##   Chinstrap      1        16      0
##   Gentoo         3         3     29</code></pre>
<p>Here we see that QDA has similar performance to LDA, but a little worse. This isn’t too surprising as based on the plots, the covariance within each of the classes seems similar. QDA may be too flexible here. Since QDA is a more flexible model than LDA (it has many more parameters), QDA is more likely to overfit than LDA.</p>
<p>Also note that, QDA creates quadratic decision boundaries, while LDA creates linear decision boundaries. We could also add quadratic terms to LDA to allow it to create quadratic decision boundaries.</p>
<hr />
</div>
<div id="naive-bayes" class="section level2" number="10.4">
<h2><span class="header-section-number">10.4</span> Naive Bayes</h2>
<p>Naive Bayes comes in many forms. With only numeric features, it often assumes a multivariate normal conditioned on the classes, but a very specific multivariate normal.</p>
<p><span class="math display">\[
{\boldsymbol X} \mid Y = k \sim N(\boldsymbol\mu_k, \boldsymbol\Sigma_k)
\]</span></p>
<p>Naive Bayes assumes that the features <span class="math inline">\(X_1, X_2, \ldots, X_p\)</span> are independent given <span class="math inline">\(Y = k\)</span>. This is the “naive” part of naive Bayes. The Bayes part is nothing new. Since <span class="math inline">\(X_1, X_2, \ldots, X_p\)</span> are assumed independent, each <span class="math inline">\(\boldsymbol\Sigma_k\)</span> is diagonal, that is, we assume no correlation between features. Independence implies zero correlation.</p>
<p>This will allow us to write the (joint) likelihood as a product of univariate distributions. In this case, the product of univariate normal distributions instead of a (joint) multivariate distribution.</p>
<p><span class="math display">\[
f_k(\boldsymbol x) = \prod_{j = 1}^{p} f_{kj}(\boldsymbol x_j)
\]</span></p>
<p>Here, <span class="math inline">\(f_{kj}(\boldsymbol x_j)\)</span> is the density for the <span class="math inline">\(j\)</span>-th feature conditioned on the <span class="math inline">\(k\)</span>-th class. Notice that there is a <span class="math inline">\(\sigma_{kj}\)</span> for each feature for each class.</p>
<p><span class="math display">\[
f_{kj}(\boldsymbol x_j) = \frac{1}{\sigma_{kj}\sqrt{2\pi}}\exp\left[-\frac{1}{2}\left(\frac{x_j - \mu_{kj}}{\sigma_{kj}}\right)^2\right]
\]</span></p>
<p>When <span class="math inline">\(p = 1\)</span>, this version of naive Bayes is equivalent to QDA.</p>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="generative.html#cb327-1"></a>peng_nb =<span class="st"> </span><span class="kw">NaiveBayes</span>(species <span class="op">~</span><span class="st"> </span>bill_length_mm <span class="op">+</span><span class="st"> </span>flipper_length_mm, <span class="dt">data =</span> peng_est)</span></code></pre></div>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="generative.html#cb328-1"></a>peng_nb<span class="op">$</span>apriori</span></code></pre></div>
<pre><code>## grouping
##    Adelie Chinstrap    Gentoo 
## 0.4457831 0.1566265 0.3975904</code></pre>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="generative.html#cb330-1"></a>peng_nb<span class="op">$</span>tables</span></code></pre></div>
<pre><code>## $bill_length_mm
##               [,1]     [,2]
## Adelie    39.08108 2.560907
## Chinstrap 48.32308 2.120595
## Gentoo    46.75152 2.768474
## 
## $flipper_length_mm
##               [,1]     [,2]
## Adelie    190.0000 4.960959
## Chinstrap 194.9231 3.729646
## Gentoo    215.9697 5.849599</code></pre>
<p>Many packages implement naive Bayes. Here we choose to use <code>NaiveBayes()</code> from the package <code>klaR</code>. The output from <code>peng_nb$tables</code> gives the mean and standard deviation of the normal distribution for each feature in each class. Notice how these mean estimates match those for LDA and QDA above.</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="generative.html#cb332-1"></a><span class="kw">head</span>(<span class="kw">predict</span>(peng_nb, peng_est)<span class="op">$</span>class)</span></code></pre></div>
<pre><code>## [1] Gentoo Adelie Adelie Adelie Adelie Gentoo
## Levels: Adelie Chinstrap Gentoo</code></pre>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="generative.html#cb334-1"></a><span class="kw">head</span>(<span class="kw">predict</span>(peng_nb, peng_est)<span class="op">$</span>posterior)</span></code></pre></div>
<pre><code>##            Adelie    Chinstrap       Gentoo
## [1,] 1.617414e-03 1.961748e-05 9.983630e-01
## [2,] 9.999804e-01 1.929359e-05 2.701873e-07
## [3,] 9.999974e-01 2.282747e-06 2.994029e-07
## [4,] 9.999981e-01 1.857175e-06 2.992396e-09
## [5,] 8.417837e-01 1.069401e-02 1.475223e-01
## [6,] 3.308450e-06 2.470560e-06 9.999942e-01</code></pre>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb336-1"><a href="generative.html#cb336-1"></a>peng_nb_est_pred =<span class="st"> </span><span class="kw">predict</span>(peng_nb, peng_est)<span class="op">$</span>class</span>
<span id="cb336-2"><a href="generative.html#cb336-2"></a>peng_nb_val_pred =<span class="st"> </span><span class="kw">predict</span>(peng_nb, peng_val)<span class="op">$</span>class</span></code></pre></div>
<pre><code>## Warning in FUN(X[[i]], ...): Numerical 0 probability for all classes with
## observation 46</code></pre>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb338-1"><a href="generative.html#cb338-1"></a><span class="kw">calc_misclass</span>(<span class="dt">predicted =</span> peng_nb_est_pred, <span class="dt">actual =</span> peng_est<span class="op">$</span>species)</span></code></pre></div>
<pre><code>## [1] 0.01204819</code></pre>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="generative.html#cb340-1"></a><span class="kw">calc_misclass</span>(<span class="dt">predicted =</span> peng_nb_val_pred, <span class="dt">actual =</span> peng_val<span class="op">$</span>species)</span></code></pre></div>
<pre><code>## [1] 0.1325301</code></pre>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="generative.html#cb342-1"></a><span class="kw">table</span>(<span class="dt">predicted =</span> peng_nb_val_pred, <span class="dt">actual =</span> peng_val<span class="op">$</span>species)</span></code></pre></div>
<pre><code>##            actual
## predicted   Adelie Chinstrap Gentoo
##   Adelie        31         2      0
##   Chinstrap      1        12      0
##   Gentoo         2         6     29</code></pre>
<p>Here we see worse performance again.</p>
<table>
<thead>
<tr>
<th style="text-align:left;">
Method
</th>
<th style="text-align:right;">
Train Error
</th>
<th style="text-align:right;">
Validation Error
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
LDA
</td>
<td style="text-align:right;">
0.0120482
</td>
<td style="text-align:right;">
0.0843373
</td>
</tr>
<tr>
<td style="text-align:left;">
LDA, Flat Prior
</td>
<td style="text-align:right;">
0.0120482
</td>
<td style="text-align:right;">
0.0722892
</td>
</tr>
<tr>
<td style="text-align:left;">
QDA
</td>
<td style="text-align:right;">
0.0120482
</td>
<td style="text-align:right;">
0.0963855
</td>
</tr>
<tr>
<td style="text-align:left;">
Naive Bayes
</td>
<td style="text-align:right;">
0.0120482
</td>
<td style="text-align:right;">
0.1325301
</td>
</tr>
</tbody>
</table>
<p>Summarizing the results, we see that Naive Bayes is the worst of LDA, QDA, and NB for this data. This isn’t surprising as there is clear dependence within the features. So why should we care about naive Bayes?</p>
<p>The strength of Naive Bayes comes from its ability to handle a large number of features, <span class="math inline">\(p\)</span>, even with a limited sample size <span class="math inline">\(n\)</span>. Even with the naive independence assumption, Naive Bayes works rather well in practice. Also because of this assumption, we can often train naive Bayes where LDA and QDA may be impossible to train because of the large number of parameters relative to the number of observations.</p>
<p>Here naive Bayes doesn’t get a chance to show its strength since LDA and QDA already perform well, and the number of features is low. The choice between LDA and QDA is mostly down to a consideration about the amount of complexity needed. (Also note that complexity within these models can also be altered by changing the features used. More features generally means a more flexible model.)</p>
<hr />
</div>
<div id="categorical-features" class="section level2" number="10.5">
<h2><span class="header-section-number">10.5</span> Categorical Features</h2>
<p>So far, we have assumed that all features are numeric. What happens with categorical features? Let’s add the <code>sex</code> variable which is categorical.</p>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb344-1"><a href="generative.html#cb344-1"></a><span class="kw">NaiveBayes</span>(species <span class="op">~</span><span class="st"> </span>bill_length_mm <span class="op">+</span><span class="st"> </span>flipper_length_mm <span class="op">+</span><span class="st"> </span>sex, <span class="dt">data =</span> peng_est)<span class="op">$</span>tables</span></code></pre></div>
<pre><code>## $bill_length_mm
##               [,1]     [,2]
## Adelie    39.08108 2.560907
## Chinstrap 48.32308 2.120595
## Gentoo    46.75152 2.768474
## 
## $flipper_length_mm
##               [,1]     [,2]
## Adelie    190.0000 4.960959
## Chinstrap 194.9231 3.729646
## Gentoo    215.9697 5.849599
## 
## $sex
##            var
## grouping       female      male
##   Adelie    0.5405405 0.4594595
##   Chinstrap 0.4615385 0.5384615
##   Gentoo    0.5757576 0.4242424</code></pre>
<p>Naive Bayes makes a somewhat obvious and intelligent choice to model the categorical variable as a multinomial. It then estimates the probability parameters of a multinomial distribution.</p>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb346-1"><a href="generative.html#cb346-1"></a><span class="kw">lda</span>(species <span class="op">~</span><span class="st"> </span>bill_length_mm <span class="op">+</span><span class="st"> </span>flipper_length_mm <span class="op">+</span><span class="st"> </span>sex, <span class="dt">data =</span> peng_est)</span></code></pre></div>
<pre><code>## Call:
## lda(species ~ bill_length_mm + flipper_length_mm + sex, data = peng_est)
## 
## Prior probabilities of groups:
##    Adelie Chinstrap    Gentoo 
## 0.4457831 0.1566265 0.3975904 
## 
## Group means:
##           bill_length_mm flipper_length_mm   sexmale
## Adelie          39.08108          190.0000 0.4594595
## Chinstrap       48.32308          194.9231 0.5384615
## Gentoo          46.75152          215.9697 0.4242424
## 
## Coefficients of linear discriminants:
##                          LD1        LD2
## bill_length_mm     0.2652470 -0.4650328
## flipper_length_mm  0.1800828  0.1383358
## sexmale           -1.8987355  0.7946053
## 
## Proportion of trace:
##    LD1    LD2 
## 0.8527 0.1473</code></pre>
<p>LDA (and QDA) however creates dummy variables, here with <code>male</code> as the reference level, then continues to model them as normally distributed. Not great, but better then not using a categorical variable.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="binary-classification.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="cross-validation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/daviddalpiaz/bsl/edit/master/generative.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
