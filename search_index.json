[
["index.html", "Basics of Statistical Learning Start Here Caveat Emptor Who? Acknowledgements License", " Basics of Statistical Learning David Dalpiaz 2020-01-27 Start Here Welcome to Basics of Statistical Learning! What a boring title! The title was chosen to mirror the University of Illinois course STAT 432 - Basics of Statistical Learning. That title was chosen to meet certain University course naming conventions, hence the boring title. A more appropriate title would be “Machine Learning from the Perspective of a Statistician who uses R,” which is more descriptive, but still a boring title. Anyway, this “book” will often be referred to as BSL. Caveat Emptor This “book” is under active development. Literally every element of the book is subject to change, at any moment. This text, BSL, is the successor to R4SL, an unfinished work that began as a supplement to Introduction to Statistical Learning, but was never finished. (In some sense, this book is just a fresh start due to the author wanting to change the presentation of the material. The author is seriously worried that he will encounter the second-system effect.) Because this book is written with a course in mind, that is actively being taught, often out of convenience the text will speak directly to the students of that course. Thus, be aware that any reference to a “course” are a reference to STAT 432 @ UIUC. Since this book is under active development you may encounter errors ranging from typos, to broken code, to poorly explained topics. If you do, please let us know! Better yet, fix the issue yourself! If you are familiar with R Markdown and GitHub, pull requests are highly encouraged!. This process is partially automated by the edit button in the top-left corner of the html version. If your suggestion or fix becomes part of the book, you will be added to the list at the end of this chapter. We’ll also link to your GitHub account, or personal website upon request. If you’re not familiar with version control systems feel free to email the author, dalpiaz2 AT illinois DOT edu. (But also consider using this opportunity to learn a bit about version control!) See additional details in the Acknowledgements section below. While development is taking place, you may see “TODO” scattered throughout the text. These are mostly notes for internal use, but give the reader some idea of what development is still to come. For additional details on the development process, please see the README file on GitHub as well as the Issues page. Who? This book is targeted at advanced undergraduate or first year MS students in Statistics who have no prior machine learning experience. While both will be discussed in great detail, previous experience with both statistical modeling and R are assumed. In other words, this books is for students in STAT 432. Acknowledgements The following is a (likely incomplete) list of helpful contributors. This book was also influenced by the helpful contributors to R4SL. Jae-Ho Lee - STAT 432, Fall 2019 W. Jonas Reger - STAT 432, Spring 2020 Your name could be here! Please see the CONTRIBUTING document on GitHub for details on interacting with this project. Pull requests encouraged! Looking for ways to contribute? You’ll notice that a lot of the plotting code is not displayed in the text, but is available in the source. Currently that code was written to accomplish a task, but without much thought about the best way to accomplish the task. Try refactoring some of this code. Fix typos. Since the book is actively being developed, typos are getting added all the time. Suggest edits. Good feedback can be just as helpful as actually contributing code changes. License CC NC SA This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License "],
["ten-simple-rules-for-success-in-stat-432.html", "Chapter 1 Ten Simple Rules for Success in STAT 432 1.1 Rule 1: There Are No Rules 1.2 Rule 2: Read the Syllabus 1.3 Rule 3: Previous Learning is Not Gospel 1.4 Rule 4: All Statements Are True 1.5 Rule 5: Don’t Miss The Forest For The Trees 1.6 Rule 6: You Will Struggle 1.7 Rule 7: Keep It Simple 1.8 Rule 8: RTFM 1.9 Rule 9: There Are No Stupid Questions 1.10 Rule 10: Learn By Doing 1.11 Conclusion 1.12 Source", " Chapter 1 Ten Simple Rules for Success in STAT 432 STAT 432 is a difficult course. Although, as a result of the historical grade distribution I believe some students enter the course believing that it is an “easy” course. This document was written to help address the reasons for this difference between perception and reality. The style is stolen from the popular “Ten Rules” articles published in PLOS journals. A relevant example is Ten Simple Rules for Effective Statistical Practice. 1.1 Rule 1: There Are No Rules Perhaps it is odd to begin a list of rules exclaiming that there are no rules. Many students that enroll in STAT 432 have an extensive mathematics background where everything follows a set of rules. However, statistics is not mathematics. While there are certainly rules in statistics, in applied statistics, an analyst must make decisions that can only be guided by heuristics. Students often ask questions such as “What method should I use in this situation?” hoping for a specific answer. While it would be easy to simply provide an “answer” of some specific model or procedure, the reality is that the answer will almost always be “it depends” and the analyst will have to make a somewhat subjective decision based on an extremely long set of heuristics. (The other answer to “Which method should I use in this situation?” will be &quot;Who knows? Try a few and evaluate which is working best. Evaluating methods will be a big focus in the course. We care more about the ability to evaluate methods than understanding the inner workings of each method.) In other words, while we could simply write some sort of flow-chart that tells you what to do in any situation encountered in the course, we reject this authoritarian approach. We prefer to present some heuristics, some reasoning behind them, and allow you to think for yourself. Skepticism is encouraged. You are allowed to form your own opinions about the course material. Applied to the data analyses done in STAT 432: There is no single correct answer. There are only good arguments and bad arguments. 1.2 Rule 2: Read the Syllabus Please. A familiarity with the syllabus will make your experience in the course much smoother. I would suggest returning to the syllabus a number of times throughout the semester, perhaps shortly before the exams. 1.3 Rule 3: Previous Learning is Not Gospel A trap many students fall into is believing that everything they have previously learned is relevant in future courses. This is not the case. Just because a method was taught in STAT 420 or STAT 425 does not mean that it is relevant in STAT 432. The most common example of this is Variance Inflation Factors. Students seem to love to drag this concept into STAT 432. While it is certainly possible to appeal to VIFs in STAT 432, they seem to be misapplied more often than not. This is because VIFs are more relevant for inference than prediction. STAT 432 cares about prediction much more than STAT 420 and STAT 425. 1.4 Rule 4: All Statements Are True Rule 4 is somewhat related to Rule 3. The full rule would read: “All statements are true, given the correct conditions.” Rule 3 is relevant here because students will often search for information on the internet. They’ll arrive at some prescription such as “Method X is good at Task Y.” In reality, this statement is always more correctly stated as “Method X is good at Task Y under Condition Z.” In other words, context is extremely important. 1.5 Rule 5: Don’t Miss The Forest For The Trees STAT 432 covers a lot of content, sometimes at a surface level. When only scratching the surface, students find the lack of details unsatisfying. This is understandable, but realize that STAT 432 is a first course in machine learning. We don’t believe it is possible to learn all of machine learning in a single course. STAT 432 is about having an understanding of what machine learning is and what you can do with it. Our goal is not to teach you every single detail. (That is impossible.) Instead, we would like to provide a high level overview that will serve as a foundation for future learning. (Both self-study and future courses.) 1.6 Rule 6: You Will Struggle You will struggle, and that is a good thing. If everything in the course were “easy,” very little learning would take place. However, we are not advocating struggle for the sake of struggle. We want to support your “struggle” with the material. The course staff is not the enemy. The material is the “enemy.” We are here to help you. Do not hesitate to ask the course staff questions! Come to office hours! Post on Piazza! 1.7 Rule 7: Keep It Simple Please keep the KISS Principle in mind. (The name is somewhat unfortunate. No, we are not calling you stupid.) Complexity does not imply valuable. Within the context of STAT 432: All else being equal, we prefer “simple” methods and models. When writing reports, shorter is better. (As long as you convey the necessary information.) 1.8 Rule 8: RTFM Warning, the following link contains foul language: RTFM. RTFM is a common phrase in coding culture. While extremely insensitive, it is perhaps some of the most relevant advice for STAT 432. In short, if you experience a coding issue: Read the documentation of the function you are trying to use. (Anything you are doing in R involves running a function.) Search the internet (“Google”) for any error messages you’ve encountered. This should always be your first line of defense any time you encounter an issue. However, we do not expect you to be able to solve all your problems with this method! That’s why office hours exists! We simply would like you to get into this habit. Having gone through this step, you are more likely to solve the problem yourself. Additionally, you will be better prepared to discuss any issue with the course staff if you are unable to solve it yourself. 1.9 Rule 9: There Are No Stupid Questions It sounds cliche, but it is true. Do not hesitate to ask the course staff questions! Come to office hours! Post on Piazza! Do note that while there really are no stupid questions, there are some annoying questions. For example: Questions that can be answered by reading the syllabus. (“When is Exam 01?” “When are office hours?”) “Can you tell me what is wrong with my code?” The second bullet requires some explaining. The direct answer to that question is technically “Yes.” However, please note that the course staff is not a debugging machine. If you simply supply us with a bunch of code and asks us what is wrong, you’ll be met with a bit of frustration. We expect that you at least pinpoint where there is an issue with the code, within reason. (We will give some advice on how best to do this as the semester progresses.) In other words, try to ask your code question in a way that demonstrates that you have already thought about solving your issue. (See Rule #9.) We will always work with you to resolve your issue, but we ask that we are not your first attempt at a resolution. Corollary: There are no “quick” questions. Student often like to preface a question with the phrase “Just one quick question.” If you’re asking the question, how do you know how long it will take to answer? (I suppose if you know it’s in the syllabus, then the answer will be quick, but …) More often than not students ask excellent questions but then expect a short, succinct answer. When you ask a good question, this is often not possible. The point is, please come to office hours where we can have an in depth conversation, that is not time limited, with additional input from you! 1.10 Rule 10: Learn By Doing Students overvalue lecture and undervalue homework. STAT 432 will probably contain less “lecture” than you expect, and far too much “work” in the form of quizzes and analyses. Watching a lecture is a passive activity. Taking quizzes is an active activity. Reading is a passive activity. Performing an analysis is an active activity. In my opinion, students enjoy (or more specifically don’t dislike) lecture because it requires zero input from them. On the other hand, quizzes are frustrating, but that is a good thing! That frustration means that there is something to learn! Stated practically and with relevance to STAT 432: The quizzes and other course activities should be given highest priority when allotting your time. You should read all posted notes twice. The first time you should read every word of the assigned material from top to bottom. Try to understand as best as possible, but don’t spend too much time reading any particular section. In a first read, it is somewhat more important to read the material to know what is there than to fully understand it. When taking the quizzes or performing an analysis, return to the relevant section of the reading. (Because you read it once before, you’ll know a certain section exists, even if you don’t understand it.) Read it again. This time you’ll have more context, and a better chance of understanding. Run the code. Modify the code and run it again. Write some similar code from scratch by yourself. Now, return to the quiz. Recorded lectures will be sparse, but if they exist, watch it once (possibly at 2x speed) but then go back to focusing on the “active” activities. 1.11 Conclusion In summary, if you bring an open mind and a bit of effort, we believe that you will succeed in STAT 432. We don’t believe that the course is easy, but we hope that it is ultimately rewarding. 1.12 Source R Markdown: 01-ten-rules.Rmd "],
["machine-learning-overview.html", "Chapter 2 Machine Learning Overview 2.1 Reading 2.2 What is Machine Learning? 2.3 Machine Learning Tasks 2.4 Open Questions 2.5 Source", " Chapter 2 Machine Learning Overview STAT 432 is a course about machine learning? Let’s try to define machine learning. 2.1 Reading Required: ISL Chapter 1 Required: ISL Chapter 2 This chapter is dense because it is an overview of the entire book. Do not expect to completely understand this chapter during a first read. We will spend the rest of the semester elaborating on these concepts. However, seeing them at the beginning will be helpful. Recommended: Variance Explained: What’s the difference between data science, machine learning, and artificial intelligence? 2.2 What is Machine Learning? Machine learning (ML) is about learning functions from data. That’s it. Really. Pretty boring, right? To quickly address some buzzwords that come up when discussing machine learning: Deep learning is just a subset of machine learning. Artificial Intelligence (AI) overlaps machine learning but has much loftier goals. In general, if someone claims to be using AI, they are not. (They’re probably using function learning! For example, we will learn logistic regression in this course. People in marketing might call that AI! Someone who understands ML will simply call it function learning. Don’t buy the hype! We don’t need to call simple methods AI to make them effective.) Machine learning is not data science. Data science sometimes uses machine learning. Does big data exist? If it does, I would bet a lot of money that you haven’t seen it, and probably won’t see it. Analytics is just a fancy word for doing data analysis. Machine learning can be used in analyses! When it is, it is often called “Predictive Analytics.” What makes machine learning interesting are the uses of these functions. We could develop functions that have applications in a wide variety of fields. In medicine, we could develop a function that helps detect skin cancer. Input: Pixels from an image of mole Output: A probability of skin cancer In sport analytics, we could develop a function that helps determine player salary. Input: Lifetime statistics of an NBA player Output: An estimate of player’s salary In meteorology, we could develop a function to predict the weather. Input: Historic weather data in Champaign, IL Output: A probability of rain tomorrow in Champaign, IL In political science we could develop a function that predicts the mood of the president. Input: The text of a tweet from President Donald Trump Output: A prediction of Donald’s mood (happy, sad, angry, etc) In urban planning we could develop a function that predicts the rental prices of Airbnbs. Input: The attributes of the location for rent Output: An estimate of the rent of the property How do we learn these functions? By looking at many previous examples, that is, data! Again, we will learn functions from data. That’s what we’re here to do. 2.3 Machine Learning Tasks When doing machine learning, we will classify our tasks into one of two categories, supervised or unsupervised learning. (There are technically other tasks such as reinforcement learning and semi-supervised learning, but they are outside the scope of this text. To understand these advanced tasks, you should first learn the basics!) Within these two broad categories of ML tasks, we will define some specifics. 2.3.1 Supervised Learning In supervised learning, we want to “predict” a specific target, outcome, or response variable. In the following examples, this is the y variable. Supervised learning tasks are called regression if the response variable is numeric. If a supervised learning tasks has a categorical response, it is called classification. 2.3.1.1 Regression In the regression task, we want to predict numeric response variables. The predictor variables, which we will call the feature variables, or simply features can be either categorical or numeric. x1 x2 x3 y A -0.66 0.48 14.09 A 1.55 0.97 2.92 A -1.19 -0.81 15.00 A 0.15 0.28 9.29 B -1.09 -0.16 17.57 B 1.61 1.94 2.12 B 0.04 1.72 8.92 A 1.31 0.36 4.40 C 0.98 0.30 4.40 C 0.88 -0.39 4.52 With the data above, our goal would be to learn a function that takes as input values of the three features (x1, x2, and x3) and returns a prediction (best guess) for the true (but usually unknown) value of the response y. For example, we could obtain some “new” data that does not contain the response. x1 x2 x3 B -0.85 -2.41 We would then pass this data to our function, which would return a prediction of the value of y. Stated mathematically, our prediction will often be an estimate the conditional mean of \\(Y\\), given values of the \\(\\boldsymbol{X}\\) variables. \\[ \\mu(\\boldsymbol{x}) = \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\boldsymbol{x}] \\] In other words, we want to learn this function, \\(\\mu(\\boldsymbol{x})\\). Much more on this later. (You can safely ignore this for now.) 2.3.1.2 Classification Classification is similar to regression, except it considers categorical response variables. x1 x2 x3 y Q 0.46 5.42 B Q 0.72 0.83 C Q 0.93 5.93 B Q 0.26 5.68 A P 0.46 0.49 B P 0.94 3.09 B P 0.98 2.34 C P 0.12 5.43 C Q 0.47 2.68 B P 0.56 5.02 B As before we want to learn a function from this data using the same inputs, except this time, we want it to output one of A, B, or C for predictions of the y variable. Again, consider some new data: x1 x2 x3 P 0.96 5.33 While ultimately we would like our function to return one of A, B, or C, what we actually would like is an intermediate return of probabilities that y is A, B, or C. In other words, we are attempting to estimate the conditional probability that \\(Y\\) is each of the possible categories, given values of the \\(\\boldsymbol{X}\\) values. \\[ p_k(\\boldsymbol{x}) = P\\left[ Y = k \\mid \\boldsymbol{X} = \\boldsymbol{x} \\right] \\] We want to learn this function, \\(p_k(\\boldsymbol{x})\\). Much more on this later. (You can safely ignore this for now.) 2.3.2 Unsupervised Learning Unsupervised learning is a very broad task that is rather difficult to define. Essentially, it is learning without a response variable. To get a better idea about what unsupervised learning is, consider some specific tasks. x1 x2 x3 x4 x5 2.74 0.46 5.42 4.43 2.28 2.81 0.72 0.83 4.87 2.61 0.86 0.93 5.93 2.33 0.22 2.49 0.26 5.68 4.11 5.84 1.93 0.46 0.49 0.02 2.59 -8.44 -9.06 -6.91 -5.00 -4.25 -7.79 -9.02 -7.66 -9.96 -4.67 -9.60 -9.88 -4.57 -8.75 -6.16 -8.03 -9.53 -7.32 -4.56 -4.17 -7.88 -9.44 -4.98 -6.33 -6.29 2.3.2.1 Clustering Clustering is essentially the task of grouping the observations of a dataset. In the above data, can you see an obvious grouping? (Hint: Compare the first five observations to the second five observations.) In general, we try to group observations that are similar. 2.3.2.2 Density Estimation Density estimation tries to do exactly what the name implies, estimate the density. In this case, the joint density of \\(X_1, X_2, X_3, X_4, X_5\\). In other words, we would like to learn the function that generated this data. (You could take the position that this is the only machine learning tasks, and all other tasks are subset of this task. We’ll hold off on explaining this for a while.) 2.3.2.3 Outlier Detection Consider some new data: x1 x2 x3 x4 x5 67 66.68 66.26 69.49 70 Was this data generated by the same process as the data above? If no, we would call it an outlier. 2.4 Open Questions The two previous sections were probably more confusing than helpful. But of course, because we haven’t started learning yet! Hopefully, you are currently pondering one very specific question: How do we learn functions from data? That’s what this text will be about! We will spend a lot of time on this question. It is what us statisticians call fitting a model. On some level the answer is: look at a bunch of old data before predicting on new data. While we will dedicate a large amount of time to answering this question, sometimes, some of the details might go unanswered. Since this is an introductory text, we can only go so far. However, as long as we answer another question, this will be OK. How do we evaluate how well learned functions work? This text places a high priority on being able to do machine learning, specifically do machine learning in R. You can actually do a lot of machine learning without fully understanding how the learning is taking place. That makes the evaluation of ML models extremely important. 2.5 Source R Markdown: 02-ml-overview.Rmd "],
["computing.html", "Chapter 3 Computing 3.1 Reading 3.2 Additional Resources 3.3 STAT 432 Idioms 3.4 Source", " Chapter 3 Computing STAT 432 is not a course about R. It is however, a course that makes heavy use of R. Because of this, you will need to be familiar with R. This text will point out some things about R along the way, but some previous study of R is necessary. 3.1 Reading The following reading suggestions are long. While it may seem daunting to read all of this material, it will likely prove to be valuable. A smart strategy would be: “Read” as much of the information here, where “read” simply means read every single word and line of code, but don’t slow down if you don’t fully understand. Return to some selections from this reading every week spending more time understanding specific sections. Whether you’re a novice or an expert, there is a high probability that any effort towards reading these sources will provide a return. If you use the strategy above, over time you will start to see the bigger picture. Required: Hands-On Programming with R - Garrett Grolemund If you have never used R or RStudio before, Part 1 (Chapters 1 - 3) will be useful. Even if you have used R before, you will likely gain something from reading these sections. Recommended: R for Data Science - Garrett Grolemund, Hadley Wickham This book helps getting you up to speed working with data in R. While it is a lot of reading, Chapters 1 - 21 may prove useful. It probably isn’t worth sitting down and reading this from start to finish right now, but reading it here and there during some free time would be a good idea. Recommended: Advanced R - Hadley Wickham Part I (Chapters 1 - 8) of this book will help create a mental model for working with R. These chapters are not an easy read, so they should be returned to often. Chapter 2 could be safely skipped for our purposes, but is important if you will use R in the long term. Reference: Applied Statistics with R - David Dalpiaz If you are a UIUC student who took the course STAT 420, the first six chapters of that book could serve as a nice refresher, however, the three readings above are preferred. Chapter 6 contain three very useful video playlists and an R Markdown template. Note that the videos were created a few years ago, thus there may be minor differences between then and now, but the general ideas are the same. Video Playlist: R and RStudio Video Playlist: Data in R Video Playlist: R Markdown Template: R Markdown R Markdown will be used throughout the course, but you will not be required to use R Markdown until the final weeks when we begin working on data analyses. At that time, we will suggest some additional reading about R Markdown. When working on quizzes until then, you can use either an R script or an R Markdown document, whichever you are more comfortable with. 3.2 Additional Resources In addition to the above readings, the following resources are more specific or more advanced, but could still prove to be useful. 3.2.1 R Efficient R programming R Programming for Data Science R Graphics Cookbook Modern Dive What They Forgot to Teach You About R The R Inferno Data Wrangling, Exploration, and Analysis with R The tidyverse Website dplyr Website readr Website tibble Website forcats Website 3.2.2 RStudio RStudio IDE Cheatsheet RStudio Resources 3.2.3 R Markdown R Markdown Cheatsheet R Markdown: The Definitive Guide - Yihui Xie, J. J. Allaire, Garrett Grolemund R Markdown Cookbook R4DS: R Markdown Chapter 3.2.3.1 Markdown Daring Fireball - Markdown: Basics GitHub - Mastering Markdown CommonMark 3.3 STAT 432 Idioms R tutorials and advice are plentiful online. While we do not want to discourage you from using the resources above, or using your own creativity, the following sections will specify some strong suggestions for how to use R, RStudio, and R Markdown in STAT 432. In other words, information below here supersedes any information from the above sources. 3.3.1 Don’t Restore Old Workspaces Due to some odd default settings in RStudio, some students never clear their R envrioment. This is a problem for a number of reasons. (It could prevent your results from being reproducible.) To get ready for STAT 432, do the following: Clear your current enviroment. Change some RStudio defaults. Deselect &quot;Restore .RData into workspace at startup. Set “Save workspace .RData on exit:” to “Never” This will save you a lot of headache in STAT 432 and the future. 3.3.2 R Versions You should always use the most up-to-date version of R and RStudio. You must use at least R versions 3.6.2. Importantly, R versions after 3.6.0 have slightly different random number generation. Although, even with the most recent version, sometimes R keeps the old random number generation. To check that you are on the most recent random number generation, run: RNGkind() ## [1] &quot;Mersenne-Twister&quot; &quot;Inversion&quot; &quot;Rejection&quot; If your output matches the output above, you’re all set. If not, run: RNGversion(getRversion()) Then re-run RNGkind() and everything should match up and you should be go to go! 3.3.3 Code Style Code needs to be read by two distinct groups: Computers Humans Computers will complain, very loudly, when you write “bad” code, that is code does not run. We need to write code that is syntactically correct for the computer to be able to “read” our code. Computers only care about syntax. If we relate this to natural language, we would say that computers really only care about grammar and punctuation. They don’t worry about style like phrasing, tone, etc. While computers will complain about bad code, does anyone really care about wasting their time? (OK, sure, computer scientists might.) If we give them bad code, they try to run it, fail, then complain. However, they’re soulless machines, they can handle it. Humans on the other hand have a finite amount of time on this earth. Even if we solve aging, we still have to deal with the heat death of the universe. Thus, while wasting a computer’s time is no big deal, wasting a human’s time is, frankly, immoral. What does this have to do with R programming? Humans are going to read your R code. One of those humans is likely to be you, but future you. To make this reading possible and efficient, you need to develop style. Here is some code that a computer can read, but a human will struggle to read: set.seed(1337);mu=10;sample_size=50;samples=100000;x_bars=rep(0, samples); for(i in 1:samples){x_bars[i]=mean(rpois(sample_size,lambda = mu))} x_bar_hist=hist(x_bars,breaks=50,main=&quot;Histogram of Sample Means&quot;, xlab=&quot;Sample Means&quot;,col=&quot;darkorange&quot;,border = &quot;dodgerblue&quot;) Now, written again, but readable by a human: # set seed for reproducibility set.seed(1337) # setup simulation parameters mu = 10 sample_size = 50 samples = 100000 # create vector to store simulation results x_bars = rep(0, samples) # run simulation for (i in 1:samples) { x_bars[i] = mean(rpois(sample_size, lambda = mu)) } # plot results x_bar_hist = hist( x_bars, breaks = 50, main = &quot;Histogram of Sample Means&quot;, xlab = &quot;Sample Means&quot;, col = &quot;darkorange&quot;, border = &quot;dodgerblue&quot; ) To the computer, these are the same. To a human, one makes you want to pull your hair out, the other you can glance at and have a pretty good idea about what is going on. Style is subjective, but we’ll define some guiding principles, and a few rules. 3.3.4 Reference Style So as to not have to define a style from the ground up, we will use the tidyverse style as our initial reference. tidyverse Style Guide We will agree with the vast majority of the guidelines here. The exceptions are listed in the next section. 3.3.5 STAT 432 R Style Overrides All commas must be followed by a space. (Additionally, commas should never be preceded by a space.) Infix operators (==, +, -, &lt;-, etc.) should always be surrounded by spaces. Exceptions: :, ::, $, [, [[, ], ]] ^: Use x ^ 2 instead of x^2. You may use = instead of &lt;-. This is very much a minority position in the R community. But we see more examples of it being promoted every day. My reasoning for this is complicated (and I should write more about it soon) but not super important. Instead, what is important: Do not mix assignment operators. Either use = or use &lt;- but do not mix and match in the same script. Never use T or F, only TRUE or FALSE. While this should never happen, take a look at this terrifying example. FALSE == TRUE # checking for equality ## [1] FALSE F == TRUE # checking for equality ## [1] FALSE F = TRUE # A VERY BAD ASSIGNMENT! DO NOT DO THIS! F == TRUE # checking for equality, with a wild result! ## [1] TRUE # TRUE = FALSE # This won&#39;t run, which is good! Do not use ;. This is mostly a readability issue. Do not use attach(). Without going into the details, you will save yourself a lot of headache someday if you follow this advice. Do not use &lt;&lt;-. You probably didn’t know this exists. Pretend that is still the case. Do not set a working directory by using setwd() or any other method. This will make your scripts and R Markdown documents much more reproducible. Do not use absolute paths. Place a space after any # used to create a comment. No more than one newline (blank line) in a row Do not put spaces in filenames. Use dashes - or underscores _. Also consider only using lowercase. Load all packages before setting a seed. Opening (left) curly braces should not be on their own line. Except for the first argument to a function, argument names should be written in function calls. (Exception for the predict() function. Do not name the section argument to the predict() function.) Place a newline at the end of the file. 3.3.6 STAT 432 R Markdown Style Some of the previous section applies here as well, but additionally, some more specific R Markdown style guidelines: No more than one newline (blank line) in a row in an R Markdown document. No more than one newline (blank line) in a row in an R chunk. A newline before and after each chunk in an R Markdown document. No newline to start a chunk. No newline at end of chunk. (The first and last line of each chunk should contain code, or a comment for the first line.) Use headers appropriately! (Short names, good structure.) Load all needed packages at the beginning of an analysis in a single chunk. One plot per chunk! Plotting chunks should return one plot and nothing else. (No numeric printing.) 3.3.7 Style Heuristics Now that we’ve overwhelmed you with information about style, will leave you with the real advise. The most important thing to consider when evaluating the style of your code is consistency. In order, you should be consistent: with yourself! with your group! with your organization! Blindly following the rules is foolish. Breaking rules can be fun! If you do it in a way that makes life easier for everyone, by all mean, do it. 3.3.8 Objects and Functions To understand computations in R, two slogans are helpful: Everything that exists is an object. Everything that happens is a function call. — John Chambers As you continue to sharper your R skills, keep this quotation in mind. Eventually, you will realize that everything you “do” in R, you do by running a function. To debug your code, you will need to explore the objects returned by functions. To fix your code, you will need to alter the inputs to functions, which are objects. In STAT 432, the objects that we will encounter will almost always be: vectors, lists data frames model objects (Mostly lists with a class of the model type.) If you become proficient at creating, manipulating, and accessing these objects, you will likely have success in STAT 432. 3.3.9 Print versus Return One of the more confusing aspects of R is the difference between what is returned when running a function, and what is printed when running a function (interactively) as a user. Consider fitting the following linear model. cars_mod = lm(dist ~ speed, data = cars) You might think that you can simply type cars_mod to see what was returned by lm(). cars_mod ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932 However, this is not what was returned. This is what was printed. To better understand what was returned, we use the `str() function. str(cars_mod) ## List of 12 ## $ coefficients : Named num [1:2] -17.58 3.93 ## ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;(Intercept)&quot; &quot;speed&quot; ## $ residuals : Named num [1:50] 3.85 11.85 -5.95 12.05 2.12 ... ## ..- attr(*, &quot;names&quot;)= chr [1:50] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ effects : Named num [1:50] -303.914 145.552 -8.115 9.885 0.194 ... ## ..- attr(*, &quot;names&quot;)= chr [1:50] &quot;(Intercept)&quot; &quot;speed&quot; &quot;&quot; &quot;&quot; ... ## $ rank : int 2 ## $ fitted.values: Named num [1:50] -1.85 -1.85 9.95 9.95 13.88 ... ## ..- attr(*, &quot;names&quot;)= chr [1:50] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ assign : int [1:2] 0 1 ## $ qr :List of 5 ## ..$ qr : num [1:50, 1:2] -7.071 0.141 0.141 0.141 0.141 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : chr [1:50] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## .. .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;speed&quot; ## .. ..- attr(*, &quot;assign&quot;)= int [1:2] 0 1 ## ..$ qraux: num [1:2] 1.14 1.27 ## ..$ pivot: int [1:2] 1 2 ## ..$ tol : num 1e-07 ## ..$ rank : int 2 ## ..- attr(*, &quot;class&quot;)= chr &quot;qr&quot; ## $ df.residual : int 48 ## $ xlevels : Named list() ## $ call : language lm(formula = dist ~ speed, data = cars) ## $ terms :Classes &#39;terms&#39;, &#39;formula&#39; language dist ~ speed ## .. ..- attr(*, &quot;variables&quot;)= language list(dist, speed) ## .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1 ## .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. ..$ : chr [1:2] &quot;dist&quot; &quot;speed&quot; ## .. .. .. ..$ : chr &quot;speed&quot; ## .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;speed&quot; ## .. ..- attr(*, &quot;order&quot;)= int 1 ## .. ..- attr(*, &quot;intercept&quot;)= int 1 ## .. ..- attr(*, &quot;response&quot;)= int 1 ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; ## .. ..- attr(*, &quot;predvars&quot;)= language list(dist, speed) ## .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot; ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;dist&quot; &quot;speed&quot; ## $ model :&#39;data.frame&#39;: 50 obs. of 2 variables: ## ..$ dist : num [1:50] 2 10 4 22 16 10 18 26 34 17 ... ## ..$ speed: num [1:50] 4 4 7 7 8 9 10 10 10 11 ... ## ..- attr(*, &quot;terms&quot;)=Classes &#39;terms&#39;, &#39;formula&#39; language dist ~ speed ## .. .. ..- attr(*, &quot;variables&quot;)= language list(dist, speed) ## .. .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1 ## .. .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. .. ..$ : chr [1:2] &quot;dist&quot; &quot;speed&quot; ## .. .. .. .. ..$ : chr &quot;speed&quot; ## .. .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;speed&quot; ## .. .. ..- attr(*, &quot;order&quot;)= int 1 ## .. .. ..- attr(*, &quot;intercept&quot;)= int 1 ## .. .. ..- attr(*, &quot;response&quot;)= int 1 ## .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; ## .. .. ..- attr(*, &quot;predvars&quot;)= language list(dist, speed) ## .. .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot; ## .. .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;dist&quot; &quot;speed&quot; ## - attr(*, &quot;class&quot;)= chr &quot;lm&quot; This is a huge mess, but most importantly, at the top we are told that cars_mod is a list. (It’s technically a object of class &quot;lm&quot;, but it functions like a list.) class(cars_mod) ## [1] &quot;lm&quot; is.list(cars_mod) ## [1] TRUE Thus to access certain information returned by lm() we need to access cars_mod as a list. cars_mod$coefficients ## (Intercept) speed ## -17.579095 3.932409 Note that what is returned here is a vector, so we could pull out a particular value using vector syntax. is.vector(cars_mod$coefficients) ## [1] TRUE cars_mod$coefficients[&quot;speed&quot;] ## speed ## 3.932409 Since lm() truly returns an object of type &quot;lm&quot; we can pass cars_mods to some generic functions, and then specific versions for objects of type &quot;lm&quot; will be used. coef(cars_mod) ## (Intercept) speed ## -17.579095 3.932409 predict(cars_mod, data.frame(speed = 5:10)) ## 1 2 3 4 5 6 ## 2.082949 6.015358 9.947766 13.880175 17.812584 21.744993 summary(cars_mod) ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -29.069 -9.525 -2.272 9.215 43.201 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -17.5791 6.7584 -2.601 0.0123 * ## speed 3.9324 0.4155 9.464 1.49e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 15.38 on 48 degrees of freedom ## Multiple R-squared: 0.6511, Adjusted R-squared: 0.6438 ## F-statistic: 89.57 on 1 and 48 DF, p-value: 1.49e-12 Hey, wait, what is returned by summary()? class(summary(cars_mod)) ## [1] &quot;summary.lm&quot; is.list(summary(cars_mod)) ## [1] TRUE The summary() function returns an object of type &quot;summary.lm&quot; which functions as a list! summary(cars_mod)$fstatistic ## value numdf dendf ## 89.56711 1.00000 48.00000 You can also use the View() function, which is specific to RStudio, to view the structure of any object. View(summary(cars_mod)) # RStudio only 3.3.10 Help To get documentation about a function in R, simply put a question mark in front of the function name and RStudio will display the documentation, for example: ?log ?sin ?paste ?lm Frequently one of the most difficult things to do when learning R is asking for help. First, you need to decide to ask for help, then you need to know how to ask for help. Your very first line of defense should be to Google your error message or a short description of your issue. (The ability to solve problems using this method is quickly becoming an extremely valuable skill.) If that fails, and it eventually will, you should ask for help. There are a number of things you should include when emailing an instructor, or posting to a help website such as Stack Exchange. Describe what you expect the code to do. State the end goal you are trying to achieve. (Sometimes what you expect the code to do, is not what you want to actually do.) Provide the full text of any errors you have received. Provide enough code to recreate the error. That is, create a minimal reproducible example. If you follow these steps, you will get your issue resolved much quicker, and possibly learn more in the process. Do not be discouraged by running into errors and difficulties when learning R. (Or any technical skill.) It is simply part of the learning process. While taking STAT 432: Come to office hours! 3.3.11 Keyboard Shortcuts This section should be expanded over time, but for now, two strong suggestions: Get in the habit of using the keyboard as much as possible, and the mouse as little as possible. A keyboard is a precise entry tool, a mouse is not. Using a mouse requires you to move your hands, a keyboard does not. Hit the [TAB] key often. Like, all the time. It will autocomplete function and object names. It will autofill argument names. (This removes the need to memorize arguments!) 3.3.12 Common Issues As they arise throughout the semester, we will try to track and explain common issues here. 3.4 Source R Markdown: 03-computing.Rmd "],
["probability.html", "Chapter 4 Probability 4.1 Reading 4.2 Probability Models 4.3 Probability Axioms 4.4 Probability Rules 4.5 Random Variables 4.6 Expectations 4.7 Likelihood 4.8 References 4.9 Source", " Chapter 4 Probability STAT 432 is not a course about probability. STAT 432 is a course that uses probability. We give a very brief review of some necessary probability concepts. As the treatment is less than complete, a list of references is given at the end of the chapter. For example, we ignore the usual recap of basic set theory and omit proofs and examples. Reading the information below will likely be unsatisfying. Instead, we suggest that you skip it, engage with the relevant quizzes, then return as needed for reference. 4.1 Reading Required: Probability Distributions in R Reference: STAT 400 @ UIUC: Notes and Homework Reference: MIT 6.041: Video Lectures Reference: MIT 6.041: Lecture Notes Reference: MIT 6.041: Readings Reference: STAT 414 @ PSU: Notes 4.2 Probability Models When discussing probability models, we speak of random experiments that produce one of a number of possible outcomes. A probability model that describes the uncertainty of an experiment consists of two elements: The sample space, often denoted as \\(\\Omega\\), which is a set that contains all possible outcomes. A probability function that assigns to an event \\(A\\) a nonnegative number, \\(P[A]\\), that represents how likely it is that event \\(A\\) occurs as a result of the experiment. We call \\(P[A]\\) the probability of event \\(A\\). An event \\(A\\) could be any subset of the sample space, not necessarily a single possible outcome. The probability law must follow a number of rules, which are the result of a set of axioms that we introduce now. 4.3 Probability Axioms Given a sample space \\(\\Omega\\) for a particular experiment, the probability function associated with the experiment must satisfy the following axioms. Nonnegativity: \\(P[A] \\geq 0\\) for any event \\(A \\subset \\Omega\\). Normalization: \\(P[\\Omega] = 1\\). That is, the probability of the entire space is 1. Additivity: For mutually exclusive events \\(E_1, E_2, \\ldots\\) \\[ P\\left[\\bigcup_{i = 1}^{\\infty} E_i\\right] = \\sum_{i = 1}^{\\infty} P[E_i] \\] Using these axioms, many additional probability rules can easily be derived. 4.4 Probability Rules Given an event \\(A\\), and its complement, \\(A^c\\), that is, the outcomes in \\(\\Omega\\) which are not in \\(A\\), we have the complement rule: \\[ P[A^c] = 1 - P[A] \\] In general, for two events \\(A\\) and \\(B\\), we have the addition rule: \\[ P[A \\cup B] = P[A] + P[B] - P[A \\cap B] \\] If \\(A\\) and \\(B\\) are also disjoint, then we have: \\[ P[A \\cup B] = P[A] + P[B] \\] If we have \\(n\\) mutually exclusive events, \\(E_1, E_2, \\ldots E_n\\), then we have: \\[ P\\left[\\textstyle\\bigcup_{i = 1}^{n} E_i\\right] = \\sum_{i = 1}^{n} P[E_i] \\] Often, we would like to understand the probability of an event \\(A\\), given some information about the outcome of event \\(B\\). In that case, we have the conditional probability rule provided \\(P[B] &gt; 0\\). \\[ P[A \\mid B] = \\frac{P[A \\cap B]}{P[B]} \\] Rearranging the conditional probability rule, we obtain the multiplication rule: \\[ P[A \\cap B] = P[B] \\cdot P[A \\mid B] \\cdot \\] For a number of events \\(E_1, E_2, \\ldots E_n\\), the multiplication rule can be expanded into the chain rule: \\[ P\\left[\\textstyle\\bigcap_{i = 1}^{n} E_i\\right] = P[E_1] \\cdot P[E_2 \\mid E_1] \\cdot P[E_3 \\mid E_1 \\cap E_2] \\cdots P\\left[E_n \\mid \\textstyle\\bigcap_{i = 1}^{n - 1} E_i\\right] \\] Define a partition of a sample space \\(\\Omega\\) to be a set of disjoint events \\(A_1, A_2, \\ldots, A_n\\) whose union is the sample space \\(\\Omega\\). That is \\[ A_i \\cap A_j = \\emptyset \\] for all \\(i \\neq j\\), and \\[ \\bigcup_{i = 1}^{n} A_i = \\Omega. \\] Now, let \\(A_1, A_2, \\ldots, A_n\\) form a partition of the sample space where \\(P[A_i] &gt; 0\\) for all \\(i\\). Then for any event \\(B\\) with \\(P[B] &gt; 0\\) we have Bayes’ Theorem: \\[ P[A_i | B] = \\frac{P[A_i]P[B | A_i]}{P[B]} = \\frac{P[A_i]P[B | A_i]}{\\sum_{i = 1}^{n}P[A_i]P[B | A_i]} \\] The denominator of the latter equality is often called the law of total probability: \\[ P[B] = \\sum_{i = 1}^{n}P[A_i]P[B | A_i] \\] Note: When working with Bayes’ Theorem it is often useful to draw a tree diagram. Two events \\(A\\) and \\(B\\) are said to be independent if they satisfy \\[ P[A \\cap B] = P[A] \\cdot P[B] \\] This becomes the new multiplication rule for independent events. A collection of events \\(E_1, E_2, \\ldots E_n\\) is said to be independent if \\[ P\\left[\\bigcap_{i \\in S} E_i \\right] = \\prod_{i \\in S}P[E_i] \\] for every subset \\(S\\) of \\(\\{1, 2, \\ldots n\\}\\). If this is the case, then the chain rule is greatly simplified to: \\[ P\\left[\\textstyle\\bigcap_{i = 1}^{n} E_i\\right] = \\prod_{i=1}^{n}P[E_i] \\] 4.5 Random Variables A random variable is simply a function which maps outcomes in the sample space to real numbers. 4.5.1 Distributions We often talk about the distribution of a random variable, which can be thought of as: \\[ \\text{distribution} = \\text{list of possible} \\textbf{ values} + \\text{associated} \\textbf{ probabilities} \\] This is not a strict mathematical definition, but is useful for conveying the idea. If the possible values of a random variables are discrete, it is called a discrete random variable. If the possible values of a random variables are continuous, it is called a continuous random variable. 4.5.2 Discrete Random Variables The distribution of a discrete random variable \\(X\\) is most often specified by a list of possible values and a probability mass function, \\(p(x)\\). The mass function directly gives probabilities, that is, \\[ p(x) = p_X(x) = P[X = x]. \\] Note we almost always drop the subscript from the more correct \\(p_X(x)\\) and simply refer to \\(p(x)\\). The relevant random variable is discerned from context The most common example of a discrete random variable is a binomial random variable. The mass function of a binomial random variable \\(X\\), is given by \\[ p(x | n, p) = {n \\choose x} p^x(1 - p)^{n - x}, \\ \\ \\ x = 0, 1, \\ldots, n, \\ n \\in \\mathbb{N}, \\ 0 &lt; p &lt; 1. \\] This line conveys a large amount of information. The function \\(p(x | n, p)\\) is the mass function. It is a function of \\(x\\), the possible values of the random variable \\(X\\). It is conditional on the parameters \\(n\\) and \\(p\\). Different values of these parameters specify different binomial distributions. \\(x = 0, 1, \\ldots, n\\) indicates the sample space, that is, the possible values of the random variable. \\(n \\in \\mathbb{N}\\) and \\(0 &lt; p &lt; 1\\) specify the parameter spaces. These are the possible values of the parameters that give a valid binomial distribution. Often all of this information is simply encoded by writing \\[ X \\sim \\text{bin}(n, p). \\] 4.5.3 Continuous Random Variables The distribution of a continuous random variable \\(X\\) is most often specified by a set of possible values and a probability density function, \\(f(x)\\). (A cumulative density or moment generating function would also suffice.) The probability of the event \\(a &lt; X &lt; b\\) is calculated as \\[ P[a &lt; X &lt; b] = \\int_{a}^{b} f(x)dx. \\] Note that densities are not probabilities. The most common example of a continuous random variable is a normal random variable. The density of a normal random variable \\(X\\), is given by \\[ f(x | \\mu, \\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\cdot \\exp\\left[\\frac{-1}{2} \\left(\\frac{x - \\mu}{\\sigma}\\right)^2 \\right], \\ \\ \\ -\\infty &lt; x &lt; \\infty, \\ -\\infty &lt; \\mu &lt; \\infty, \\ \\sigma &gt; 0. \\] The function \\(f(x | \\mu, \\sigma^2)\\) is the density function. It is a function of \\(x\\), the possible values of the random variable \\(X\\). It is conditional on the parameters \\(\\mu\\) and \\(\\sigma^2\\). Different values of these parameters specify different normal distributions. \\(-\\infty &lt; x &lt; \\infty\\) indicates the sample space. In this case, the random variable may take any value on the real line. \\(-\\infty &lt; \\mu &lt; \\infty\\) and \\(\\sigma &gt; 0\\) specify the parameter space. These are the possible values of the parameters that give a valid normal distribution. Often all of this information is simply encoded by writing \\[ X \\sim N(\\mu, \\sigma^2) \\] 4.5.4 Distributions in R R is an excellent, if not best, tool for performing probability distribution calculations. For a large number of distributions, it has four built in functions: d*(x, ...) returns the PDF at \\(x\\) (for continuous distributions) or the PMG at \\(x\\) (for discrete distributions) p*(q, ...) returns the CDF at quantile \\(q\\), that is \\(P[X \\leq q]\\) q*(p, ...) returns \\(c\\) such that \\(P[x \\leq c] = p\\) r*(n, ...) returns \\(n\\) randomly generated observations The * can be any of the disributions built in to R. The ... represents additional arguments, including the parameters of the various distributions. 4.5.5 Several Random Variables Consider two random variables \\(X\\) and \\(Y\\). We say they are independent if \\[ f(x, y) = f(x) \\cdot f(y) \\] for all \\(x\\) and \\(y\\). Here \\(f(x, y)\\) is the joint density (mass) function of \\(X\\) and \\(Y\\). We call \\(f(x)\\) the marginal density (mass) function of \\(X\\). Then \\(f(y)\\) the marginal density (mass) function of \\(Y\\). The joint density (mass) function \\(f(x, y)\\) together with the possible \\((x, y)\\) values specify the joint distribution of \\(X\\) and \\(Y\\). Similar notions exist for more than two variables. 4.6 Expectations For discrete random variables, we define the expectation of the function of a random variable \\(X\\) as follows. \\[ \\mathbb{E}[g(X)] \\triangleq \\sum_{x} g(x)p(x) \\] For continuous random variables we have a similar definition. \\[ \\mathbb{E}[g(X)] \\triangleq \\int g(x)f(x) dx \\] For specific functions \\(g\\), expectations are given names. The mean of a random variable \\(X\\) is given by \\[ \\mu_{X} = \\text{mean}[X] \\triangleq \\mathbb{E}[X]. \\] So for a discrete random variable, we would have \\[ \\text{mean}[X] = \\sum_{x} x \\cdot p(x) \\] For a continuous random variable we would simply replace the sum by an integral. The variance of a random variable \\(X\\) is given by \\[ \\sigma^2_{X} = \\text{var}[X] \\triangleq \\mathbb{E}[(X - \\mathbb{E}[X])^2] = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2. \\] The standard deviation of a random variable \\(X\\) is given by \\[ \\sigma_{X} = \\text{sd}[X] \\triangleq \\sqrt{\\sigma^2_{X}} = \\sqrt{\\text{var}[X]}. \\] The covariance of random variables \\(X\\) and \\(Y\\) is given by \\[ \\text{cov}[X, Y] \\triangleq \\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])] = \\mathbb{E}[XY] - \\mathbb{E}[X] \\cdot \\mathbb{E}[Y]. \\] 4.7 Likelihood Consider \\(n\\) iid random variables \\(X_1, X_2, \\ldots X_n\\). We can then write their likelihood as \\[ \\mathcal{L}(\\theta \\mid x_1, x_2, \\ldots x_n) \\triangleq f(x_1, x_2, \\ldots, x_n; \\theta) = \\prod_{i = 1}^n f(x_i; \\theta) \\] where \\(f(x_1, x_2, \\ldots, x_n; \\theta)\\) is the joint density (or mass) of \\(X_1, X_2, \\ldots X_n\\) and \\(f(x_i; \\theta)\\) is the density (or mass) function of random variable \\(X_i\\) evaluated at \\(x_i\\) with parameter \\(\\theta\\). (Note: The last equality above only holds for iid random variables.) Whereas a probability or density is a function of a possible observed value given a particular parameter value, a likelihood is the opposite. It is a function of a possible parameter values given observed data. Likelihoods are calculated when the data (the \\(x_i\\)) are known and the parameters (\\(\\theta\\)) are unknown. That is, a likelihood and a joint density will “look” the same, that is contain the same symbols. The meaning of these symbols change depending on what is known. If the data is known, and the parameters is unknown, you have a likelihood. If the parameters are known, and the data are unknown, you have a joint density. The definition above is an acknowledgement of this. The likelihood is defined to be the joint density when the data are known but the parameter(s) is unknown. Maximizing a likelihood is a common technique for fitting a model to data, however, most often we maximum the log-likelihood, as the likelihood and log-likelihood obtain their maximum at the same point. \\[ \\log \\mathcal{L}(\\theta \\mid x_1, x_2, \\ldots x_n) = \\sum_{i = 1}^{n} \\log f(x_i; \\theta) \\] As an example, suppose that the data vector x_data contains observations from a random sample \\(X_1, X_2, \\ldots, X_n\\) that is assumed to be sampled from a Poisson distribution with (unknown) parameter \\(\\lambda\\). set.seed(42) x_data = rpois(n = 25, lambda = 6) # generating data (assume this is not known) head(x_data) # check data ## [1] 9 10 5 8 7 6 We can use R to calculate the likelihood for various possible values of \\(\\lambda\\) given this data. # calculate the likelihood when lambda = 5 prod(dpois(x = x_data, lambda = 5)) ## [1] 2.609375e-30 The above code takes advantage of the vectorized nature of the dpois() function. Often, especially for computational reasons, we prefer to directly obtain the log-likelihood. # calculate the log-likelihood when lambda = 5 sum(log(dpois(x = x_data, lambda = 5))) ## [1] -68.11844 To understand why this is necessary, repeat the above, but with a much larger sample size. Also note that the d*() functions in R have an option to return logged values. # calculate the log-likelihood when lambda = 5 sum(dpois(x = x_data, lambda = 5, log = TRUE)) ## [1] -68.11844 4.8 References Any of the following are either dedicated to, or contain a good coverage of the details of the topics above. Probability Texts Introduction to Probability by Dimitri P. Bertsekas and John N. Tsitsiklis A First Course in Probability by Sheldon Ross Machine Learning Texts with Probability Focus Probability for Statistics and Machine Learning by Anirban DasGupta Machine Learning: A Probabilistic Perspective by Kevin P. Murphy Statistics Texts with Introduction to Probability Probability and Statistical Inference by Robert V. Hogg, Elliot Tanis, and Dale Zimmerman Introduction to Mathematical Statistics by Robert V. Hogg, Joseph McKean, and Allen T. Craig 4.8.1 Videos The YouTube channel mathematicalmonk has a great Probability Primer playlist containing lectures on many fundamental probability concepts. Some of the more important concepts are covered in the following videos: Conditional Probability Independence More Independence Bayes Rule 4.9 Source R Markdown: 04-probability.Rmd "],
["statistics.html", "Chapter 5 Statistics 5.1 Reading 5.2 Statistics 5.3 Estimators 5.4 Source", " Chapter 5 Statistics STAT 432 is a course about statistics, in particular, some specific statistics. To discuss the statistics of interest in STAT 432, we will need some general concepts about statistics. Note: This section has been published while being nearly empty to provide easy access to a few definitions needed for Quiz 01. Additional information was added ahead of Quiz 02, but it is still very sparse as it is difficult to summarize all of statistics in one chapter. In reality we just need to state a few definitions here and then move on to the next chapter, where the fun begins. 5.1 Reading Reference: STAT 400 @ UIUC: Notes and Homework Reference: STAT 3202 @ OSU: Fitting a Probability Model Reference: STAT 415 @ PSU: Notes 5.2 Statistics In short: a statistic is a function of (sample) data. (This mirrors parameters being functions of (population) distributions. In SAT terminology, statistics : data :: parameter : distribution.) Consider a random variable \\(X\\), with PDF \\(f(x)\\) which defines the distribution of \\(X\\). Now consider the parameter \\(\\mu\\), which we usually refer to as the mean of a distribution. We use \\(\\mu_X\\) to note that \\(\\mu\\) is dependent on the distribution of \\(X\\). \\[ \\mu_X = \\text{E}[X] = \\int_{-\\infty}^{\\infty}xf(x)dx \\] Note that this expression is a function of \\(f(x)\\). When we change the distribution of \\(X\\), that is, it has a different \\(f(x)\\), that effects \\(\\mu\\). Now, given a random sample \\(X_1, X_2, \\ldots, X_n\\), define a statistic, \\[ \\hat{\\mu}(x_1, x_2, \\ldots, x_n) = \\frac{1}{n}\\sum_{i = 1}^{n}x_i \\] Often, we will simplify notation and instead simply write \\[ \\hat{\\mu} = \\frac{1}{n}\\sum_{i = 1}^{n}x_i \\] and the fact that \\(\\hat{\\mu}\\) is a function of the sample is implied. (You might also notice that this is the sample mean, which is often denoted by \\(\\bar{x}\\).) Another confusing aspect of statistics is that they are random variables! Sometimes we would write the above as \\[ \\hat{\\mu}(X_1, X_2, \\ldots, X_n) = \\frac{1}{n}\\sum_{i = 1}^{n}X_i \\] When written this way, we are emphasizing that the random sample has not yet be observed, thus is still random. When this is the case, we can investigate the properties of the statistic as a random variable. When the sample has been observed, we use \\(x_1, x_2, \\ldots, x_n\\) to note that we are inputting these observed values into a function, which outputs some value. (Sometimes we, and others, will be notationally sloppy and simply use lower case \\(x\\) and you will be expected to understand via context if we are dealing with random variables or observed values of random variables. This is admittedly confusing.) As a final note, suppose we observe some data \\[ x_1 = 2, x_2 = 1, x_3 =5 \\] and we calculate \\(\\hat{\\mu}\\) given these values. We would obtain \\[ \\hat{\\mu} = \\frac{8}{3} \\approx 2.66 \\] Note that 2.66 is not a statistic. It is the value of a statistic given a particular set of data. The statistic is still \\(\\hat{\\mu}\\) which has output the value 2.66. Statistics output values given some data. 5.3 Estimators Estimators are just statistics with a purpose, that is, estimators are statistics that attempt to estimate some quantity of interest, usually some parameter. (In other words, learn from data.) Like statistics, estimators are functions of data that output values, which we call estimates. 5.3.1 Properties Bias and Variance Visually Illustrated Because they are just statistics, estimators are simply functions of data. What makes an estimator good? Essentially, an estimator is good if it produces estimates that are close to the thing being estimated. The following properties help to better define this “closeness” as a function of the errors made by estimators. To estimate some parameter \\(\\theta\\) we will consider some estimator \\(\\hat{\\theta}\\). 5.3.1.1 Bias The bias of an estimator defines the systematic error of the estimator, that is, how the estimator “misses” on average. \\[ \\text{bias}\\left[\\hat{\\theta}\\right] \\triangleq \\mathbb{E}\\left[\\hat{\\theta}\\right] - \\theta \\] 5.3.1.2 Variance The variance of an estimator defines how close resulting estimates are to each other. (Assuming the estimated was repeated.) \\[ \\text{var}\\left[\\hat{\\theta}\\right] \\triangleq \\mathbb{E}\\left[ \\left( \\hat{\\theta} - \\mathbb{E}\\left[\\hat{\\theta}\\right] \\right)^2 \\right] \\] 5.3.1.3 Mean Squared Error The mean squared error (MSE) is exactly what the name suggests, it is the average squared error of the estimator. Interestingly, the MSE decomposes into terms related to the bias and the variance. We will return to this idea later for a detailed discussion in the context of machine learning. \\[ \\text{MSE}\\left[\\hat{\\theta}\\right] \\triangleq \\mathbb{E}\\left[\\left(\\hat{\\theta} - \\theta\\right)^2\\right] = \\left(\\text{bias}\\left[\\hat{\\theta}\\right]\\right)^2 + \\text{var}\\left[\\hat{\\theta}\\right] \\] 5.3.1.4 Consistency An estimator \\(\\hat{\\theta}_n\\) is said to be a consistent estimator of \\(\\theta\\) if, for any positive \\(\\epsilon\\), \\[ \\lim_{n \\rightarrow \\infty} P\\left( \\left| \\hat{\\theta}_n - \\theta \\right| \\leq \\epsilon\\right) =1 \\] or, equivalently, \\[ \\lim_{n \\rightarrow \\infty} P\\left( \\left| \\hat{\\theta}_n - \\theta \\right| &gt; \\epsilon\\right) =0 \\] We say that \\(\\hat{\\theta}_n\\) converges in probability to \\(\\theta\\) and we write \\(\\hat{\\theta}_n \\overset P \\rightarrow \\theta\\). 5.3.2 Example: MSE of an Estimator Consider \\(X_1, X_2, X_3 \\sim N(\\mu, \\sigma^2)\\). Define two estimators for the true mean, \\(\\mu\\). \\[ \\bar{X} = \\frac{1}{n}\\sum_{i = 1}^{3} X_i \\] \\[ \\hat{\\mu} = \\frac{1}{4}X_1 + \\frac{1}{5}X_2 + \\frac{1}{6}X_3 \\] We will now calculate and compare the mean squared error of both \\(\\bar{X}\\) and \\(\\hat{\\mu}\\) as estimators of \\(\\mu\\). First, recall from properties of the sample mean that \\[ \\text{E}\\left[\\bar{X}\\right] = \\mu \\] and \\[ \\text{var}\\left[\\bar{X}\\right] = \\frac{\\sigma^2}{3} \\] Thus we have \\[ \\text{bias}\\left[\\bar{X}\\right] = \\mathbb{E}\\left[\\bar{X}\\right] - \\mu = \\mu - \\mu = 0 \\] Then, \\[ \\text{MSE}\\left[\\bar{X}\\right] \\triangleq \\left(\\text{bias}\\left[\\bar{X}\\right]\\right)^2 + \\text{var}\\left[\\bar{X}\\right] = 0 + \\frac{\\sigma^2}{3} = \\frac{\\sigma^2}{3} \\] Next, \\[ \\text{E}\\left[\\hat{\\mu}\\right] = \\frac{\\mu}{4} + \\frac{\\mu}{5} + \\frac{\\mu}{6} = \\frac{37}{60}\\mu \\] and \\[ \\text{var}\\left[\\hat{\\mu}\\right] = \\frac{\\sigma^2}{16} + \\frac{\\sigma^2}{25} + \\frac{\\sigma^2}{36} = \\frac{469}{3600}\\sigma^2 \\] Now we have \\[ \\text{bias}\\left[\\hat{\\mu}\\right] = \\mathbb{E}\\left[\\hat{\\mu}\\right] - \\mu = \\frac{37}{60}\\mu - \\mu = \\frac{-23}{60}\\mu \\] Then finally we obtain the mean squared error for \\(\\hat{\\mu}\\), \\[ \\text{MSE}\\left[\\hat{\\mu}\\right] \\triangleq \\left(\\text{bias}\\left[\\hat{\\mu}\\right]\\right)^2 + \\text{var}\\left[\\hat{\\mu}\\right] = \\left( \\frac{-23}{60}\\mu \\right)^2 + \\frac{469}{3600}\\sigma^2 \\] Note that \\(\\text{MSE}\\left[\\hat{\\mu}\\right]\\) is small when \\(\\mu\\) is close to 0. 5.3.3 Estimation Methods So far we have discussed properties of estimators, but how do we create estimators? You could just define a bunch of estimators and then evaluate them to see what works best (an idea we will return to later in the context of ML) but (the field of) statistics has develop some methods that result in estimators with desirable properties. 5.3.4 Maximum Likelihood Estimation Given a random sample \\(X_1, X_2, \\ldots, X_n\\) from a population with parameter \\(\\theta\\) and density or mass \\(f(x; \\theta)\\), we define the likelihood as \\[ \\mathcal{L}(\\theta \\mid x_1, x_2, \\ldots x_n) \\triangleq f(x_1, x_2, \\ldots, x_n; \\theta) = \\prod_{i = 1}^n f(x_i; \\theta) \\] The Maximum Likelihood Estimator, \\(\\hat{\\theta}\\) \\[ \\hat{\\theta} \\triangleq \\underset{\\theta}{\\text{argmax}} \\ \\mathcal{L}(\\theta \\mid x_1, x_2, \\ldots x_n) = \\underset{\\theta}{\\text{argmax}} \\ \\log \\mathcal{L}(\\theta \\mid x_1, x_2, \\ldots x_n) \\] 5.3.4.1 Invariance Principle If \\(\\hat{\\theta}\\) is the MLE of \\(\\theta\\) and the function \\(h(\\theta)\\) is continuous, then \\(h(\\hat{\\theta})\\) is the MLE of \\(h(\\theta)\\). 5.3.5 Method of Moments While it is very unlikely that we will use the Method of Moments in STAT 432, you should still be aware of its existence. 5.3.6 Empirical Distribution Function Consider a random variable \\(X\\) with CDF \\(F(k) = P(X &lt; k)\\) and an iid random sample \\(X_1, X_2, \\ldots, X_n\\). We can estimate \\(F(k)\\) using the Empirical Distribution Function (EDF), \\[ \\hat{F}(k) = \\frac{\\text{# of elements in sample} \\leq k}{n} = \\frac{1}{n} \\sum_{i = 1}^n I(x_i \\leq k) \\] where \\(I(x_i \\leq k)\\) is an indicator such that \\[ I(x_i \\leq k) = \\begin{cases} 1 &amp; \\text{if } x_i \\leq k \\\\ 0 &amp; \\text{if } x_i &gt; k \\end{cases} \\] Given a data vector in R that is assumed to be a random sample, say, y, and some value, say k, it is easy to calculate \\(\\hat{F}(k)\\). set.seed(66) y = rnorm(n = 25, mean = 6, sd = 2.6) # generate sample k = 4 # pick some k head(y) # check data ## [1] 12.042334 6.564140 7.087301 5.503419 5.181420 4.315569 # using the EDF mean(y &lt; k) ## [1] 0.2 # using an estimated normal distribution (not quite using the MLE) pnorm(q = k, mean = mean(y), sd = sd(y)) ## [1] 0.2088465 # using the true (but assumed unknown) CDF pnorm(q = k, mean = 6, sd = 2.6) ## [1] 0.2208782 Note that technically sd(x) does not return the MLE of \\(\\sigma\\) since it uses the unbiased estimator with a denominator of \\(n - 1\\) instead of \\(n\\), but we’re being lazy for the sake of some cleaner code. plot(ecdf(y), col.01line = &quot;white&quot;, verticals = TRUE, do.points = FALSE, xlim = c(0, 15), lwd = 2, lty = 1, ylab = &quot;F(y)&quot;, xlab = &quot;y&quot;, main = &quot;Comparing the EDF to The Truth and MLE&quot;) curve(pnorm(x, mean = 6, sd = 2.6), add = TRUE, xlim = c(0, 15), col = &quot;dodgerblue&quot;, lty = 2, lwd = 2) curve(pnorm(x, mean = mean(y), sd = sd(y)), add = TRUE, xlim = c(0, 15), col = &quot;darkorange&quot;, lty = 3, lwd = 2) legend(&quot;bottomright&quot;, legend = c(&quot;EDF&quot;, &quot;Truth&quot;, &quot;MLE&quot;), col = c(&quot;black&quot;, &quot;dodgerblue&quot;, &quot;darkorange&quot;), lty = 1:3, lwd = 2) grid() We have purposefully used a “small” sample size here so that the EDF is visibly a step function. Modify the code above to increase the sample size. You should notice that the three functions converge as the sample size increases. 5.4 Source R Markdown: 05-statistics.Rmd "],
["linear-regression.html", "Chapter 6 Linear Regression 6.1 Reading 6.2 Explanation versus Prediction 6.3 Setup 6.4 Mathematical Setup 6.5 Linear Regression Models 6.6 Using lm() 6.7 The predict() Function 6.8 Data Splitting 6.9 Regression Metrics 6.10 Example: “Simple” Simulated Data 6.11 Example: Diamonds Data 6.12 Example: Fuel Efficiency Data 6.13 Example: Credit Card Data 6.14 Source", " Chapter 6 Linear Regression This chapter will discuss linear regression models, but for a very specific purpose: using linear regression models to make predictions. Specifically, we will discuss: The regression function and estimating conditional means. Using the lm() and predict() functions in R. Data splits to evaluate model performance for machine learning tasks. 6.1 Reading Required: ISL Chapter 3 Skip section 3.6 which is dedicated to R. Consider this reading a review of previous regression knowledge. The information provided in this chapter of BSL will be the relevant material for STAT 432, but it is still worthwhile to read ISL. However note that this chapter of ISL overemphasizes inference, diagnostics, and at times hints too closely to causal claims for novice readers. (We’re not saying the authors are guilty of making the “correlation is not causation error,” instead, we’ve found that we need to be extremely clear about this issue with students in STAT 432.) Reference: STAT 420 @ UIUC: Notes In particular Chapter 10 which discusses model building will be relevant. The section on explanation versus prediction is extremely relevant, although note that it contains some differences in definitions, especially concerning test data. That said, the general ideas are important. 6.2 Explanation versus Prediction Before we even begin to discuss regression, we make a bold announcement: STAT 432 is not a course about inference. It is very possible that there will be zero causal claims in this book. While it would certainly be nice (but extremely difficult) to uncover causal relationships, our focus will be on predictive relationships. Suppose (although it is likely untrue) that there is a strong correlation between wearing a wrist watch, and car accidents. Depending on your frame of reference, you should view this information in very different ways. Suppose you are a car insurance company. This is great news! You can now more accurately predict the number of accidents of your policy holders. For the sake of understanding how much your company will need to pay out in a year, you don’t care what causes accidents, you just want to be able to predict (estimate) the number of accidents. Suppose you are a car driver. As a driver, you want to stay safe. That is, you want to do things that decrease accidents. In this framing, you care about things that cause accidents, not things that predict accidents. In other words, this correlation information should not lead to you throwing away your wrist watch. Disclaimer: Extremely high correlation should not simply be ignored. For example, there is a very high correlation between smoking and lung cancer. (Fun fact: RA Fisher, the most famous statistician, did not believe that smoking caused cancer. It’s actually a part of a larger fasinating story.) However, this strong correlation is not proof that smoking causes lung cancer. Instead, additional study is needed to rule out confounders, establish mechanistic relationships, and more. 6.3 Setup We now introduce the regression task. Regression is a subset of a broader machine learning tasks called supervised learning, which also include classification. (We will return later to discuss supervised learning in general after getting through some specifics of regression and classification.) Stated simply, the regression tasks seeks to estimate (predict) a numeric quantity. For example: Estimating the salary of a baseball player. Estimating the price of a home for sale. Estimating the credit score of a bank customer. Estimating the number of downloads of a podcast. Each of these quantities is some numeric value. The goal of regression is to estimate (predict) these quantities when they are unknown through the use of additional, possibly correlated quantities. 6.4 Mathematical Setup To get a better grasp of what regression is, we move to defining the task mathematically. Consider a random variable \\(Y\\) which represents a response (or outcome or target) variable, and \\(p\\) feature variables \\(\\boldsymbol{X} = (X_1, X_2, \\ldots, X_p)\\). Features are also called covariates or predictors. (We find the “predictors” nomenclature to be problematic when discussing prediction tasks.) In the most common regression setup, we assume that the response variable \\(Y\\) is some function of the features, plus some random noise. \\[ Y = f(\\boldsymbol{X}) + \\epsilon \\] We call \\(f(\\boldsymbol{X})\\) the signal. This \\(f\\) is the function that we would like to learn. We call \\(\\epsilon\\) the noise. We do not want to learn this which we risk if we overfit. (More on this later.) So our goal will be to find some \\(f\\) such that \\(f(\\boldsymbol{X})\\) is close to \\(Y\\). But how do we define close? There are many ways but we will start with, and most often consider, squared error loss. Specifically, we define a loss function, \\[ L(Y, \\boldsymbol{X}) \\triangleq (Y - \\boldsymbol{X}) ^ 2 \\] Now we can clarify the goal of regression, which is to minimize the above loss, on average. We call this the risk of estimating \\(Y\\) using \\(f(\\boldsymbol{X})\\). \\[ R(Y, f(\\boldsymbol{X})) \\triangleq \\mathbb{E}[L(Y, f(\\boldsymbol{X}))] = \\mathbb{E}_{X, Y}[(Y - f(\\boldsymbol{X})) ^ 2] \\] Before attempting to minimize the risk, we first re-write the risk after conditioning on \\(\\boldsymbol{X}\\). \\[ \\mathbb{E}_{\\boldsymbol{X}, Y} \\left[ (Y - f(\\boldsymbol{X})) ^ 2 \\right] = \\mathbb{E}_{\\boldsymbol{X}} \\mathbb{E}_{Y \\mid \\boldsymbol{X}} \\left[ ( Y - f(\\boldsymbol{X}) ) ^ 2 \\mid \\boldsymbol{X} = \\boldsymbol{x} \\right] \\] Minimizing the right-hand side is much easier, as it simply amounts to minimizing the inner expectation with respect to \\(Y \\mid \\boldsymbol{X}\\), essentially minimizing the risk pointwise, for each \\(\\boldsymbol{x}\\). It turns out, that the risk is minimized by the conditional mean of \\(Y\\) given \\(\\boldsymbol{X}\\), \\[ \\mu(\\boldsymbol{x}) \\triangleq \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\boldsymbol{x}] \\] which we call the regression function. Note that \\(\\boldsymbol{x}\\) represents realized values of the random variables \\(\\boldsymbol{X}\\), as discussed in the previous chapter. \\[ \\boldsymbol{x} = (x_1, x_2, \\ldots, x_p) \\] We can now state the goal of the regression task: we want to estimate the regression function. How do we do that? 6.5 Linear Regression Models What do linear regression models do? They estimate the conditional mean of \\(Y\\) given \\(\\boldsymbol{X}\\)! (How convenient.) Consider the following probability model \\[ Y = 1 - 2x - 3x ^ 2 + 5x ^ 3 + \\epsilon \\] where \\(\\epsilon \\sim \\text{N}(0, \\sigma^2)\\). Alternatively we could write \\[ Y \\mid X \\sim \\text{N}(1 - 2x - 3x ^ 2 + 5x ^ 3, \\sigma^2) \\] This perhaps makes it clearer that \\[ \\mu(x) = \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\boldsymbol{x}] = 1 - 2x - 3x ^ 2 + 5x ^ 3 \\] What do linear models do? More specifically than before, linear regression models estimate the conditional mean of \\(Y\\) given \\(\\boldsymbol{X}\\) by assuming this conditional mean is a linear combination of the feature variables. Suppose for a moment that we did not know the above true probability model, or even the more specificly the regression function. Instead, all we had was some data, \\((x_i, y_i)\\) for \\(i = 1, 2, \\ldots, n\\). x y -0.4689827 -0.0580887 -0.2557522 1.7190632 0.1457067 1.3986870 0.8164156 0.6641923 -0.5966361 -0.2419769 0.7967794 1.5428566 0.8893505 0.7554431 0.3215956 -0.4083999 0.2582281 -1.8451058 -0.8764275 -1.7926190 How do we fit (or “train” in the ML language) a linear model with this data? In order words, how to be learn the regression function from this data with a linear regression model? First, we need to make assumptions about the form of the regression function, up to, but not including some unknown parameters. Consider three possible linear models, in particular, three possible regression functions. Degree 1 Polynomial \\[ \\mu(x) = \\beta_0 + \\beta_1 x \\] Degree 3 Polynomial \\[ \\mu(x) = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 \\] Degree 9 Polynomial \\[ \\mu(x) = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 + \\ldots + \\beta_9 x^9 \\] These are chosen mostly arbitrarily for illustrative purposes which we’ll see in a moment. So how do we actually fit these models, that is train them, with the given data. We have a couple of options: Maximum Likelihood or Least Squares! In this case, they actually produce the same result, so we use least squares for simplicity of explanation. To fit the degree 3 polynomial using least squares, we minimize \\[ \\sum_{i = 1}^{n}(y_i - (\\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 + \\beta_3 x_i^3)) ^ 2 \\] Skipping the details of the minimization, we would acquire \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\), \\(\\hat{\\beta}_2\\), and \\(\\hat{\\beta}_3\\) which are estimates of \\({\\beta}_0\\), \\({\\beta}_1\\), \\({\\beta}_2\\), and \\({\\beta}_3\\). Taken together, we would have \\[ \\hat{\\mu}(x) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2^2 + \\hat{\\beta}_3 x_3^3 \\] which is then an estimate of \\(\\mu(x)\\). While in this case, it will almost certainly not be the case that \\(\\hat{\\beta}_0 = 1\\) or \\(\\hat{\\beta}_1 = -2\\) or \\(\\hat{\\beta}_2 = -3\\) or \\(\\hat{\\beta}_3 = 5\\), which are the true values of the \\(\\beta\\) coefficients, they are at least reasonable estimates. As a bit of an aside, note that in this case, it is sort of ambiguous as to whether there is one feature, \\(x\\), which is seen in the data, or three features \\(x\\), \\(x^2\\), and \\(x^3\\), which are seen in the model. The truth is sort of in the middle. The data has a single feature, but through feature engineering, we have created two additional features for fitting the model. Note that when using R, you do not need to modify the data to do this, instead you should use R’s formula syntax to specify this feature engineering when fitting the model. More on this when we discuss the lm() function in R. (We introduce this somewhat confusing notion early so we can emphasize that linear models are about linear combinations of features, not necessarily linear relationships. Although, linear models are very good at learning linear relationships.) Suppose instead we had assumed that \\[ \\mu(x) = \\beta_0 + \\beta_1 x \\] This model is obviously flawed as it doesn’t contain enough terms to capture the true regression function. (Later we will say this model is not “flexible” enough.) Or, suppose we had assumed \\[ \\mu(x) = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 + \\ldots + \\beta_9 x^9 \\] This model is also flawed, but for a different reason. (Later we will say this model is too “flexible.”) After using least squares, we will obtain some \\(\\hat{\\beta}_9\\) even though there is not a 9th degree term in the true regression function! Let’s take a look at this visually. Here we see the three models fit to the data above. The dashed black curve is the true mean function, that is the true mean of \\(Y\\) given \\(x\\), and the solid colored curves are the estimated mean functions. Now we ask the question: which of these models is best? Given these pictures, there are two criteria that we could consider. How close is the estimated regression (mean) function to the data? (Degree 9 is best! There is no error!) How close is the estimated regression (mean) function to the true regression (mean) function? (Degree 3 is best.) From the presentation here, it’s probably clear that the latter is actually what matters. We can demonstrate this by generating some “new” data. These plots match the plots above, except newly simulated data is shown. (The regression functions were still estimated with the previous data.) Note that the degree 3 polynomial matches the data about the same as before. The degree 9 polynomial now correctly predicts none of the new data and makes some huge errors. We will define these concepts more generally later, but for now we note that: The Degree 9 Polynomial is overfitting. It performs well on the data used to fit the model, but poorly on new data. The Degree 1 Polynomial is underfitting. It performs poorly on the data used to fit the model and poorly on new data. There’s a bit of a problem though! In practice, we don’t know the true mean function, and we don’t have the magical ability to simulate new data! Yikes! After we discuss a bit about how to fit these models in R, we’ll return to this issue. (Spoiler: Don’t fit the model to all the available data. Pretend the data you didn’t use is “new” when you evaluate models.) 6.6 Using lm() Before we continue, let’s consider a different data generating process. We first define this data generating process as an R function. gen_mlr_data = function(sample_size = 250) { x1 = round(runif(n = sample_size), 2) x2 = round(runif(n = sample_size), 2) x3 = round(runif(n = sample_size), 2) x4 = factor(sample(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), size = sample_size, replace = TRUE)) x5 = round(runif(n = sample_size), 2) x6 = round(runif(n = sample_size), 2) y = 2 + x1 + sin(x2) + 3 * x3 ^ 2 + 3 * (x4 == &quot;B&quot;) - 2 * (x4 == &quot;C&quot;) + rnorm(n = sample_size, mean = 0, sd = 0.5) tibble(y, x1, x2, x3, x4, x5, x6) } We then run the function and store the data that is returned. set.seed(42) sim_mlr_data = gen_mlr_data() We then inspect the data. head(sim_mlr_data) ## # A tibble: 6 x 7 ## y x1 x2 x3 x4 x5 x6 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2.85 0.91 0.33 0.14 A 0.53 0.24 ## 2 6.22 0.94 0.19 0.18 B 0.7 0.51 ## 3 6.71 0.290 0.27 0.52 B 0.05 0.51 ## 4 7.84 0.83 0.53 0.81 B 0.92 0.76 ## 5 2.75 0.64 0.02 0.12 A 0.03 0.27 ## 6 4.60 0.52 0.8 0.89 A 0.78 0.69 Note that we see only numeric (dbl or int) and factor (fctr) variables. For now, we will require that data contains only these types, and in particular, we will coerce any categorical variables to be factors. (More on this later.) Mathematically, this data was generated from the probability model \\[ Y \\mid \\boldsymbol{X} \\sim \\text{N}(2 + 1\\cdot x_1 + 1 \\cdot \\sin(x_2) + 3 \\cdot x_3^3 + 3 \\cdot x_{4B} -2 \\cdot x_{4C}, \\sigma^2 = 0.25) \\] where \\(x_{4B}\\) is a dummy variable which takes the value 1 when \\(x_4 = \\text{B}\\) and 0 otherwise \\(x_{4C}\\) is a dummy variable which takes the value 1 when \\(x_4 = \\text{C}\\) and 0 otherwise In particular, the true mean function is \\[ \\mu(\\boldsymbol{x}) = 2 + 1\\cdot x_1 + 1 \\cdot \\sin(x_2) + 3 \\cdot x_3^3 + 3 \\cdot x_{4B} -2 \\cdot x_{4C} \\] Now, finally, let’s fit some models it R to this data! To do so, we will use one of the most important functions in R, the lm() function. Let’s specify some assumed mean functions of models that we would like to fit. Model 1 or mod_1 in R \\[ \\mu_1(\\boldsymbol{x}) = \\beta_0 + \\beta_1 x_1 \\] Model 2 or mod_2 in R \\[ \\mu_2(\\boldsymbol{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 \\] Model 3 or mod_3 in R \\[ \\mu_3(\\boldsymbol{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_{4B} x_{4B} +\\beta_{4C} x_{4C} + \\beta_5 x_5 + \\beta_6 x_6 \\] Model 4 or mod_4 in R \\[ \\mu_4(\\boldsymbol{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 \\sin(x_2) + \\beta_3 x_3^3 + \\beta_{4B} x_{4B} + \\beta_{4C} x_{4C} \\] Now, finally, R! mod_1 = lm(y ~ x1, data = sim_mlr_data) coef(mod_1) ## (Intercept) x1 ## 3.7834423 0.9530758 Nothing too interesting here about fitting Model 1. We see that the coef() function returns estimate of the \\(\\beta_0\\) and \\(\\beta_1\\) parameters defined above. mod_2 = lm(y ~ x1 + x2, data = sim_mlr_data) coef(mod_2) ## (Intercept) x1 x2 ## 3.8747999 0.9400654 -0.1802538 Again, Model 2 isn’t too interesting. We see that the coef() function returns estimate of the \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\beta_2\\) parameters defined above. mod_3 = lm(y ~ ., data = sim_mlr_data) coef(mod_3) ## (Intercept) x1 x2 x3 x4B x4C ## 1.71015079 0.76017877 0.77637360 3.00479841 3.06812204 -1.93068734 ## x5 x6 ## -0.12248770 -0.04797294 Now, Model 3, we see a couple interesting things. First, the formula syntax y ~ . fits a model with y as the response, and all other variables in the sim_mlr_data data frame (tibble) as features. Also note: we did not manually create the needed dummy variables! R did this for us! levels(sim_mlr_data$x4) ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; Because x4 is a factor variable, R uses the first level, A, as the reference level, and then creates dummy variables for the remaining levels. Cool! mod_4 = lm(y ~ x1 + I(sin(x2)) + I(x3 ^ 3) + x4, data = sim_mlr_data) coef(mod_4) ## (Intercept) x1 I(sin(x2)) I(x3^3) x4B x4C ## 2.3435702 0.8176247 0.9159963 3.0446314 3.0369950 -1.9421931 Our last model, mod_4 is the most interesting. It makes use of the inhibit function, I(). This allows for on-the-fly feature engineering based on available features. We’re creating new features via R’s formula syntax as we fit the model. To see why this is necessary, consider the following: lm(y ~ (x1 + x2) ^ 2, data = sim_mlr_data) ## ## Call: ## lm(formula = y ~ (x1 + x2)^2, data = sim_mlr_data) ## ## Coefficients: ## (Intercept) x1 x2 x1:x2 ## 4.1800 0.3353 -0.8259 1.3130 This created an interaction term! That means the ^ operator has different uses depending on the context. In specifying a formula, it has a particular use, in this case specifying an interaction term, and all lower order terms. However, inside of I() it will be used for exponentiation. For details, use ?I and ?formula. These are complex R topics, but it will help to start to learn them. For some additional reading on R’s formula syntax, the following two blog posts by Max Kuhn are good reads: The R Formula Method: The Good Parts The R Formula Method: The Bad Parts For the first half of this book, we will always keep the data mostly untouched, and rely heavily on the use of R’s formula syntax. If you are ever interested in what’s happening under the hood when you use the formula syntax, and you recall the linear algebra necessary to perform linear regression, the model.matrix() function will be useful. head(model.matrix(mod_4)) ## (Intercept) x1 I(sin(x2)) I(x3^3) x4B x4C ## 1 1 0.91 0.32404303 0.002744 0 0 ## 2 1 0.94 0.18885889 0.005832 1 0 ## 3 1 0.29 0.26673144 0.140608 1 0 ## 4 1 0.83 0.50553334 0.531441 1 0 ## 5 1 0.64 0.01999867 0.001728 0 0 ## 6 1 0.52 0.71735609 0.704969 0 0 Back to talking about mod_4. Recall that we had assumed that \\[ \\mu_4(\\boldsymbol{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 \\sin(x_2) + \\beta_3 x_3^3 + \\beta_{4B} x_{4B} + \\beta_{4C} x_{4C} \\] Also recall that the true mean function is \\[ \\mu(\\boldsymbol{x}) = 2 + 1\\cdot x_1 + 1 \\cdot \\sin(x_2) + 3 \\cdot x_3^3 + 3 \\cdot x_{4B} -2 \\cdot x_{4C} \\] Because we know this, we can investigate how well our model is performing. We know the true values of the parameters, in this case \\(\\beta_0 = 2\\) \\(\\beta_1 = 1\\) \\(\\beta_2 = 1\\) \\(\\beta_3 = 3\\) \\(\\beta_{4B} = 3\\) \\(\\beta_{4C} = -2\\) \\(\\beta_5 = 0\\) (\\(x_5\\) is not used in the true mean function.) \\(\\beta_6 = 0\\) (\\(x_6\\) is not used in the true mean function.) We also have the estimated coefficients from mod_4. coef(mod_4) ## (Intercept) x1 I(sin(x2)) I(x3^3) x4B x4C ## 2.3435702 0.8176247 0.9159963 3.0446314 3.0369950 -1.9421931 \\(\\hat{\\beta}_0 = 2.34\\) \\(\\hat{\\beta}_1 = 0.82\\) \\(\\hat{\\beta}_2 = 0.92\\) \\(\\hat{\\beta}_3 = 3.04\\) \\(\\hat{\\beta}_{4B} = 3.04\\) \\(\\hat{\\beta}_{4C} = -1.94\\) \\(\\hat{\\beta}_5 = 0\\) (We assumed \\(x_5\\) is not used in the true mean function.) \\(\\hat{\\beta}_6 = 0\\) (We assumed \\(x_6\\) is not used in the true mean function.) Our estimated regression (mean) function is then \\[ \\hat{\\mu}_4(\\boldsymbol{x}) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 \\sin(x_2) + \\hat{\\beta}_3 x_3^3 + \\hat{\\beta}_{4B} x_{4B} + \\hat{\\beta}_{4C} x_{4C} \\] Perfect? No. Pretty good? Maybe. However, in reality, this is not a check that we can perform! We still need an evaluation strategy that doesn’t depend on knowing the true model! Note that the other models are “bad” in this case because they are either missing features (mod_1 and mod_2) or the are both missing features and contain unnecessary features (mod_3). 6.7 The predict() Function We stated previously that fitting a linear regression model means that we are learning the regression (mean) function. Now that we fit and stored some models, how do we access these estimated regression (mean) functions? The predict() function! The predict() function will be the workhorse of STAT 432. Let’s see how to use it with models fit using the lm() function. set.seed(3) new_obs = gen_mlr_data(sample_size = 1) new_obs ## # A tibble: 1 x 7 ## y x1 x2 x3 x4 x5 x6 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.751 0.17 0.81 0.38 C 0.6 0.6 Suppose we wanted to estimate the mean of \\(Y\\) when \\(x_1 = 0.17\\) \\(x_2 = 0.81\\) \\(x_3 = 0.38\\) \\(x_4 = \\text{C}\\) \\(x_5 = 0.38\\) \\(x_6 = 0.38\\) In other words, we want to estimate \\[ \\mathbb{E}[Y \\mid \\boldsymbol{X} = \\texttt{new_obs}] = \\mathbb{E}[Y \\mid X_1 = 0.17, X_2 = 0.81, X_3 = 0.38, X_4 = \\text{C}, X_5 = 0.6, X_6 = 0.6] \\] The predict() function to the rescue! predict(mod_1, new_obs) ## 1 ## 3.945465 What’s being returned here? \\[ \\hat{\\mu}_1(\\texttt{new_obs}) = \\hat{\\mathbb{E}}[Y \\mid \\boldsymbol{X} = \\texttt{new_obs}] = 3.9454652 \\] The predict function is essentially the estimated regression (mean) function! Supply a different model, then you get that estimated regression (mean) function. predict(mod_4, new_obs) ## 1 ## 1.370883 What’s being returned here? \\[ \\hat{\\mu}_4(\\texttt{new_obs}) = \\hat{\\mathbb{E}}[Y \\mid \\boldsymbol{X} = \\texttt{new_obs}] = 1.3708827 \\] We could compare these two estimates of the conditional mean of \\(Y\\) to the true value of y observed in the observation. More on that in the next section. If given an entire dataset, instead of a single observation, predict() returns the estimated conditional mean of each observation. set.seed(9) some_more_data = gen_mlr_data(sample_size = 10) predict(mod_4, some_more_data) ## 1 2 3 4 5 6 7 8 ## 7.8896349 5.4061018 1.3788387 0.8560024 6.6246872 8.2203544 3.2140060 3.5738889 ## 9 10 ## 5.9928135 8.4908895 Neat! A warning: Do not name the second argument to the predict function. This will cause issues because sometimes the name of that argument is newdata, as it is here, but sometimes it is data. If you use the wrong name, bad things will happen. It is safer to simply never name this argument. (However, in general, arguments after the first should be named. The predict() function is the exception.) 6.8 Data Splitting (Note: Many readers will have possibly seen some machine learning previously. For now, please pretend that you have never heard of or seen cross-validation. Cross-validation will clutter the initial introduction of many concepts. We will return to and formalize it later.) OK. So now we can fit models, and make predictions (create estimates of the conditional mean of \\(Y\\) given values of the features), how do we evaluate how well our models perform, without knowing the true model! First, let’s state a somewhat specific goal. We would like to train models that generalize well, that is, perform well on “new” or “unseen” data that was not used to train the model. To accomplish this goal, we’ll just “create” a dataset that isn’t used to train the model! To create it, we will just split it off. (We’ll actually do so twice.) First, denote the entire available data as \\(\\mathcal{D}\\). \\[ \\mathcal{D} = \\{ (x_i, y_i) \\in \\mathbb{R}^p \\times \\mathbb{R}, \\ i = 1, 2, \\ldots n \\} \\] We first split this data into a train and test set. We will discuss these two dataset ad nauseam, but let’s set two rules right now. You can do whatever you would like with the training data. However, it is best used to train, evaluate, and select models. Do not, ever, for any reason, fit a model using test data! Additionally, you should not select models using test data. In STAT 432, we will only use test data to provide a final estimate of the generalization error of a chosen model. (Much more on this along the way.) Again, Do not, ever, for any reason, fit a model using test data! I repeat: Do not, ever, for any reason, fit a model using test data! (You’ve been warned.) To perform this split, we will randomly select some observations for the train (trn) set, the remainder will be used for the test (tst) set. \\[ \\mathcal{D} = \\mathcal{D}_{\\texttt{trn}} \\cup \\mathcal{D}_{\\texttt{tst}} \\] As a general guiding heuristic, use 80% of the data for training, 20% for testing. In addition to the train-test split, we will further split the train data into estimation and validation sets. These are somewhat confusing terms, developed for STAT 432, but hear us out. To perform this split, we will randomly select some observations (from the train set) for the estimation (est) set, the remainder will be used for the validation (val) set. \\[ \\mathcal{D}_{\\texttt{trn}} = \\mathcal{D}_{\\texttt{est}} \\cup \\mathcal{D}_{\\texttt{val}} \\] Again, use 80% of the data for estimation, 20% for validation. The need for this second split might not become super clear until later on, but the general idea is this: Fit a bunch of candidate models to the estimation data. (Think of this as the data to estimate the model parameters. That’s how we chose the name.) Using these candidate models, evaluate how well they perform using the validation data. After evaluating and picking a single model, re-fit this model to the entire training dataset. Provide an estimate of how well this model performs using the test data. Now that we have data for estimation, and validation, we need some metrics for evaluating these models. 6.9 Regression Metrics If our goal is to “predict” then we want small errors. In general there are two types of errors we consider: Squared Errors: \\((y_i - \\hat{\\mu}(\\boldsymbol{x})) ^2\\) Absolute Errors: \\(|y_i - \\hat{\\mu}(\\boldsymbol{x})|\\) In both cases, we will want to consider the average errors made. We define two metrics. Root Mean Square Error (RMSE) \\[ \\text{rmse}\\left(\\hat{f}_{\\texttt{set_f}}, \\mathcal{D}_{\\texttt{set_D}} \\right) = \\sqrt{\\frac{1}{n_{\\texttt{set_D}}}\\displaystyle\\sum_{i \\in {\\texttt{set_D}}}^{}\\left(y_i - \\hat{f}_{\\texttt{set_f}}({x}_i)\\right)^2} \\] Mean Absolute Error (MAE) \\[ \\text{mae}\\left(\\hat{f}_{\\texttt{set_f}}, \\mathcal{D}_{\\texttt{set_D}} \\right) = \\frac{1}{n_{\\texttt{set_D}}}\\displaystyle\\sum_{i \\in {\\texttt{set_D}}}^{}\\left|y_i - \\hat{f}_{\\texttt{set_f}}({x}_i)\\right| \\] \\(\\hat{f}_{\\texttt{set_f}}\\) is a function \\(f\\) estimated using a model fit to some dataset \\(\\texttt{set_f}\\). The \\((x_i, y_i)\\) are data from dataset \\(\\mathcal{D}_{\\texttt{set_D}}\\). For both, smaller is better. (Less error on average.) In both, we note both the data that the model was fit to, as well as the data the model is evaluated on. Depending on the data used for these different sets, we “define” different metrics. For example, for RMSE, we have: Train RMSE: Evaluate a model fit to estimation data, using estimation data. \\[ \\text{RMSE}_{\\texttt{trn}} = \\text{rmse}\\left(\\hat{f}_{\\texttt{est}}, \\mathcal{D}_{\\texttt{est}}\\right) = \\sqrt{\\frac{1}{n_{\\texttt{est}}}\\displaystyle\\sum_{i \\in {\\texttt{est}}}^{}\\left(y_i - \\hat{f}_{\\texttt{est}}({x}_i)\\right)^2} \\] Validation RMSE: Evaluate a model fit to estimation data, using validation data. \\[ \\text{RMSE}_{\\texttt{val}} = \\text{rmse}\\left(\\hat{f}_{\\texttt{est}}, \\mathcal{D}_{\\texttt{val}}\\right) = \\sqrt{\\frac{1}{n_{\\texttt{val}}}\\displaystyle\\sum_{i \\in {\\texttt{val}}}^{}\\left(y_i - \\hat{f}_{\\texttt{est}}({x}_i)\\right)^2} \\] Test RMSE: Evaluate a model fit to training data, using test data. \\[ \\text{RMSE}_{\\texttt{tst}} = \\text{rmse}\\left(\\hat{f}_{\\texttt{trn}}, \\mathcal{D}_{\\texttt{tst}}\\right) = \\sqrt{\\frac{1}{n_{\\texttt{tst}}}\\displaystyle\\sum_{i \\in {\\texttt{tst}}}^{}\\left(y_i - \\hat{f}_{\\texttt{trn}}({x}_i)\\right)^2} \\] For the rest of this chapter, we will largely ignore train error. It’s a bit confusing, since it doesn’t use the full training data! However, think of training error this way: training error evaluates how well a model performs on the data used to fit the model. Let’s return to the sim_mlr_data data and apply these splits and metrics to this data. # test-train split mlr_trn_idx = sample(nrow(sim_mlr_data), size = 0.8 * nrow(sim_mlr_data)) mlr_trn = sim_mlr_data[mlr_trn_idx, ] mlr_tst = sim_mlr_data[-mlr_trn_idx, ] Here we randomly select 80% of the rows of the full data, and store these indicies as mlr_trn_idx. We then create the mlr_trn and mlr_tst datasets by either selecting or anti-selecting these rows from the original dataset. # estimation-validation split mlr_est_idx = sample(nrow(mlr_trn), size = 0.8 * nrow(mlr_trn)) mlr_est = mlr_trn[mlr_est_idx, ] mlr_val = mlr_trn[-mlr_est_idx, ] We then repeat the process from above within the train data. Now, let’s compare mod_3 and mod_4. To do so, we first fit both models to the estimation data. mod_3_est = lm(y ~ ., data = mlr_est) mod_4_est = lm(y ~ x1 + I(sin(x2)) + I(x3 ^ 3) + x4, data = mlr_est) We then calculate the validation error for both. Because we will do it so often, we go ahead and write a function to calculate RMSE, given vectors of the actual values (from the data used to evaluate) and the predictions from the model. calc_rmse = function(actual, predicted) { sqrt(mean((actual - predicted) ^ 2)) } # calculate validation RMSE, model 3 calc_rmse(actual = mlr_val$y, predicted = predict(mod_3_est, mlr_val)) ## [1] 0.5788282 # calculate validation RMSE, model 4 calc_rmse(actual = mlr_val$y, predicted = predict(mod_4_est, mlr_val)) ## [1] 0.5452852 Here we see that mod_4_est achieves a lower validation error, so we move forward with this model. We then refit to the full train data, then evaluate on test. mod_4_trn = lm(y ~ x1 + I(sin(x2)) + I(x3 ^ 3) + x4, data = mlr_trn) # calculate test RMSE, model 4 calc_rmse(actual = mlr_tst$y, predicted = predict(mod_4_trn, mlr_tst)) ## [1] 0.538057 We ignore the validation metrics. (we already used them for selecting a model.) This test RMSE is our estimate of how well our selected model will perform on unseen data, on average (in a squared error sense). Note that for selecting a model there is no difference between MSE and RMSE, but for the sake of understanding, RMSE has preferential units, the same units as the response variables. (Whereas MSE has units squared.) We will always report RMSE. 6.9.1 Graphical Evaluation In addition to numeric evaluations, we can evaluate a regression model graphical, in particular with a predicted versus actual plot. plot( x = mlr_tst$y, y = predict(mod_4_trn, mlr_tst), pch = 20, col = &quot;darkgrey&quot;, xlim = c(-1, 10), ylim = c(-1, 10), main = &quot;Predicted vs Actual, Model 4, Test Data&quot;, xlab = &quot;Actual&quot;, ylab = &quot;Predicted&quot; ) abline(a = 0, b = 1, lwd = 2) grid() The closer to the line the better. Also, the less of a pattern the better. In other words, this plot will help diagnose if our model is making similar sized errors for all predictions, or if there are systematic differences. This might get you thinking about “checking the assumptions” of a linear model. Assessing things like: normality, constant variance, etc. Note that while these are nice things to have, we aren’t really concerned with these things. If we care how well our model predicts, then we will directly evaluate how well it predicts. Least squares is least squares. It minimizes errors. It doesn’t care about model assumptions. 6.10 Example: “Simple” Simulated Data Let’s return to our initial dataset with a single feature \\(x\\). This time we’ll generate more data, and then split it. cubic_mean = function(x) { 1 - 2 * x - 3 * x ^ 2 + 5 * x ^ 3 } gen_slr_data = function(sample_size = 100, mu) { x = runif(n = sample_size, min = -1, max = 1) y = mu(x) + rnorm(n = sample_size) tibble(x, y) } set.seed(3) sim_slr_data = gen_slr_data(sample_size = 100, mu = cubic_mean) # test-train split slr_trn_idx = sample(nrow(sim_slr_data), size = 0.8 * nrow(sim_slr_data)) slr_trn = sim_slr_data[slr_trn_idx, ] slr_tst = sim_slr_data[-slr_trn_idx, ] # estimation-validation split slr_est_idx = sample(nrow(slr_trn), size = 0.8 * nrow(slr_trn)) slr_est = slr_trn[slr_est_idx, ] slr_val = slr_trn[-slr_est_idx, ] # check data head(slr_trn, n = 10) ## # A tibble: 10 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.573 -1.18 ## 2 0.807 0.576 ## 3 0.272 -0.973 ## 4 -0.813 -1.78 ## 5 -0.161 0.833 ## 6 0.736 1.07 ## 7 -0.242 2.97 ## 8 0.520 -1.64 ## 9 -0.664 0.269 ## 10 -0.777 -2.02 This time let’s evaluate nine different models. Polynomial models from degree 1 to 9. We fit each model to the estimation data, and store the results in a list. poly_mod_est_list = list( poly_mod_1_est = lm(y ~ poly(x, degree = 1), data = slr_est), poly_mod_2_est = lm(y ~ poly(x, degree = 2), data = slr_est), poly_mod_3_est = lm(y ~ poly(x, degree = 3), data = slr_est), poly_mod_4_est = lm(y ~ poly(x, degree = 4), data = slr_est), poly_mod_5_est = lm(y ~ poly(x, degree = 5), data = slr_est), poly_mod_6_est = lm(y ~ poly(x, degree = 6), data = slr_est), poly_mod_7_est = lm(y ~ poly(x, degree = 7), data = slr_est), poly_mod_8_est = lm(y ~ poly(x, degree = 8), data = slr_est), poly_mod_9_est = lm(y ~ poly(x, degree = 9), data = slr_est) ) So, for example, to access the third model, we would use poly_mod_est_list[[3]] ## ## Call: ## lm(formula = y ~ poly(x, degree = 3), data = slr_est) ## ## Coefficients: ## (Intercept) poly(x, degree = 3)1 poly(x, degree = 3)2 ## -0.2058 5.3030 -7.4306 ## poly(x, degree = 3)3 ## 6.7638 But let’s back up. That code was terrible to write. Too much repeated code. Consider the following code poly_mod_est_list = map(1:9, ~ lm(y ~ poly(x, degree = .x), data = slr_est)) This accomplishes the same task, but is much cleaner! poly_mod_est_list[[3]] ## ## Call: ## lm(formula = y ~ poly(x, degree = .x), data = slr_est) ## ## Coefficients: ## (Intercept) poly(x, degree = .x)1 poly(x, degree = .x)2 ## -0.2058 5.3030 -7.4306 ## poly(x, degree = .x)3 ## 6.7638 Here we are using the map() function from the purrr package. The ~ here is used to create a function in place. We’ll consider another way to make it a bit clearer, that is, without writing the function within map(). fit_poly_mod_to_est_data = function(d) { lm(y ~ poly(x, degree = d), data = slr_est) } poly_mod_est_list = map(1:9, fit_poly_mod_to_est_data) Again, the same thing. poly_mod_est_list[[3]] ## ## Call: ## lm(formula = y ~ poly(x, degree = d), data = slr_est) ## ## Coefficients: ## (Intercept) poly(x, degree = d)1 poly(x, degree = d)2 ## -0.2058 5.3030 -7.4306 ## poly(x, degree = d)3 ## 6.7638 We’ll continue to use this map() function throughout. We’ll explain more and more as we go. Note that the map() function returns a list. The following makes predictions for each of the models, once using the estimation data, once using validation. poly_mod_est_pred = map(poly_mod_est_list, predict, slr_est) poly_mod_val_pred = map(poly_mod_est_list, predict, slr_val) If instead we wanted to return a numeric vector, we would use, map_dbl(). Let’s use this to calculate train and validation RMSE. # calculate train RMSE slr_est_rmse = map_dbl(poly_mod_est_pred, calc_rmse, actual = slr_est$y) # calculate validation RMSE slr_val_rmse = map_dbl(poly_mod_val_pred, calc_rmse, actual = slr_val$y) slr_est_rmse ## [1] 1.5748180 1.2717458 0.9500069 0.9480786 0.9302359 0.9187948 0.9151668 ## [8] 0.9120942 0.9117093 Note that training error goes down as degree goes up. More on this next chapter. slr_val_rmse ## [1] 1.6584930 1.2791685 0.9574010 0.9729928 1.0104449 1.0505615 1.0617693 ## [8] 1.0953461 1.0968283 which.min(slr_val_rmse) ## [1] 3 The model with polynomial degree 3 has the lowest validation error, so we move forward with this model. We re-fit to the full train dataset, then evaluate on the test set one last time. poly_mod_3_trn = lm(y ~ poly(x, degree = 3), data = slr_trn) calc_rmse(actual = slr_tst$y, predicted = predict(poly_mod_3_trn, slr_tst)) ## [1] 0.7198306 Note: There are hints here that this process is a bit unstable. See if you can figure out why. Hint: See what happens when you change the seed to generate or split the data. We’ll return to this issue when we introduce cross-validation, but for now, we’ll pretend we didn’t notice. We’ll round out this chapter with three “real” data examples. 6.11 Example: Diamonds Data For this example, we use (a subset of) the diamonds data from the ggplot2 package. # load (subset of) data set.seed(42) dmnd = ggplot2::diamonds[sample(nrow(diamonds), size = 5000), ] # data prep dmnd = dmnd %&gt;% mutate(cut = factor(cut, ordered = FALSE), color = factor(color, ordered = FALSE), clarity = factor(clarity, ordered = FALSE)) %&gt;% select(-price, everything()) # test-train split dmnd_trn_idx = sample(nrow(dmnd), size = 0.8 * nrow(dmnd)) dmnd_trn = dmnd[dmnd_trn_idx, ] dmnd_tst = dmnd[-dmnd_trn_idx, ] # estimation-validation split dmnd_est_idx = sample(nrow(dmnd_trn), size = 0.8 * nrow(dmnd_trn)) dmnd_est = dmnd_trn[dmnd_est_idx, ] dmnd_val = dmnd_trn[-dmnd_est_idx, ] The code above loads the data, then performs a test-train split, then additionally an estimation-validation split. We then look at the train data. That is we do not even look at the test data. # check data head(dmnd_trn, n = 10) ## # A tibble: 10 x 10 ## carat cut color clarity depth table x y z price ## &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 0.5 Premium H SI1 59 59 5.22 5.18 3.07 1156 ## 2 1.01 Ideal G SI2 63.2 57 6.33 6.28 3.99 4038 ## 3 0.62 Very Good D SI1 61.3 58 5.47 5.49 3.36 1949 ## 4 0.41 Ideal D VS2 62.4 54 4.78 4.74 2.97 1076 ## 5 0.31 Ideal G IF 61.6 54 4.36 4.4 2.7 853 ## 6 1.08 Ideal I SI1 62.6 53.9 6.51 6.56 4.09 5049 ## 7 0.52 Very Good G VS2 62.4 60 5.14 5.18 3.22 1423 ## 8 1.01 Premium F SI2 60.9 60 6.45 6.42 3.91 3297 ## 9 0.570 Ideal H VS1 61.7 54 5.33 5.36 3.3 1554 ## 10 0.34 Ideal H VS2 62.5 54 4.54 4.49 2.82 689 Our goal here will be to build a model to predict the price of a diamond given it’s characteristics. Let’s create a few EDA plots. Note that these plots do not contain the test data. If they did, we would be using the test data to influence model building and selection, a big no-no. Let’s consider four possible models, each of which we fit to the estimation data. dmnd_mod_1_est = lm(price ~ carat, data = dmnd_est) dmnd_mod_2_est = lm(price ~ carat + x + y + z, data = dmnd_est) dmnd_mod_3_est = lm(price ~ poly(carat, degree = 2) + x + y + z, data = dmnd_est) dmnd_mod_4_est = lm(price ~ poly(carat, degree = 2) + . - carat, data = dmnd_est) Now, let’s calculate the validation RMSE of each. dmnd_mod_list = list( dmnd_mod_1_est, dmnd_mod_2_est, dmnd_mod_3_est, dmnd_mod_4_est ) dmnd_mod_val_pred = map(dmnd_mod_list, predict, dmnd_val) map_dbl(dmnd_mod_val_pred, calc_rmse, actual = dmnd_val$price) ## [1] 1583.558 1517.080 1634.396 1350.659 It looks like model dmnd_mod_4_est achieves the lowest validation error. We re-fit this model, then repot the test RMSE. dmnd_mod_4_trn = lm(price ~ poly(carat, degree = 2) + . - carat, data = dmnd_trn) calc_rmse(actual = dmnd_tst$price, predicted = predict(dmnd_mod_4_trn, dmnd_tst)) ## [1] 1094.916 So, on average, this model is “wrong” by about $1000 dollars. However, less-so when it is a low cost diamond, more so with high priced diamonds, as we can see in the plot below. plot( x = dmnd_tst$price, y = predict(dmnd_mod_4_trn, dmnd_tst), pch = 20, col = &quot;darkgrey&quot;, xlim = c(0, 25000), ylim = c(0, 25000), main = &quot;Diamonds: Predicted vs Actual, Model 4, Test Data&quot;, xlab = &quot;Actual&quot;, ylab = &quot;Predicted&quot; ) abline(a = 0, b = 1, lwd = 2) grid() Some things to consider: Could you use the predicted versus actual plot to assist in selecting a model with the validation data? Can you improve this model? Would a log transform of price help? 6.12 Example: Fuel Efficiency Data TODO: This section is still being worked on. Should be updated soon. # load data mpg = ggplot2::mpg # data prep mpg = mpg %&gt;% select(-manufacturer, -model) %&gt;% mutate_if(is.character, as_factor) %&gt;% mutate(cyl = as_factor(cyl)) # test-train split mpg_trn_idx = sample(nrow(mpg), size = 0.8 * nrow(mpg)) mpg_trn = mpg[mpg_trn_idx, ] mpg_tst = mpg[-mpg_trn_idx, ] # estimation-validation split mpg_est_idx = sample(nrow(mpg_trn), size = 0.8 * nrow(mpg_trn)) mpg_est = mpg_trn[mpg_est_idx, ] mpg_val = mpg_trn[-mpg_est_idx, ] # check data head(mpg_trn, n = 10) ## # A tibble: 10 x 9 ## displ year cyl trans drv cty hwy fl class ## &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; ## 1 3 2008 6 auto(l5) 4 17 22 d suv ## 2 6 2008 8 auto(l4) r 12 17 r suv ## 3 4.7 2008 8 manual(m6) 4 12 16 r pickup ## 4 5.7 1999 8 manual(m6) r 16 26 p 2seater ## 5 4.7 1999 8 auto(l4) 4 14 17 r suv ## 6 4.7 2008 8 auto(l5) 4 14 17 r suv ## 7 4.6 1999 8 manual(m5) 4 13 16 r pickup ## 8 4.7 2008 8 auto(l5) 4 14 19 r pickup ## 9 2.5 2008 4 auto(s4) 4 20 27 r compact ## 10 2.7 1999 4 auto(l4) 4 16 20 r suv 6.13 Example: Credit Card Data TODO: This section is still being worked on. Should be updated soon. # load data, coerce to tibble crdt = as_tibble(ISLR::Credit) # data prep crdt = crdt %&gt;% select(-ID) # test-train split crdt_trn_idx = sample(nrow(crdt), size = 0.8 * nrow(crdt)) crdt_trn = crdt[crdt_trn_idx, ] crdt_tst = crdt[-crdt_trn_idx, ] # estimation-validation split crdt_est_idx = sample(nrow(crdt_trn), size = 0.8 * nrow(crdt_trn)) crdt_est = crdt_trn[crdt_est_idx, ] crdt_val = crdt_trn[-crdt_est_idx, ] # check data head(crdt_trn, n = 10) ## # A tibble: 10 x 11 ## Income Limit Rating Cards Age Education Gender Student Married Ethnicity ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; ## 1 28.9 2733 210 5 43 16 &quot; Mal… No Yes Asian ## 2 63.8 7530 515 1 56 12 &quot; Mal… No Yes Caucasian ## 3 63.5 8100 581 2 50 17 &quot;Fema… No Yes Caucasian ## 4 58.8 7402 538 2 81 12 &quot;Fema… No Yes Asian ## 5 33.7 6196 450 6 55 9 &quot;Fema… No No Caucasian ## 6 75.4 3874 298 3 41 14 &quot;Fema… No Yes Asian ## 7 55.2 5352 385 4 50 17 &quot;Fema… No Yes Caucasian ## 8 27.8 3807 301 4 35 8 &quot;Fema… No Yes African … ## 9 53.3 2860 214 1 84 10 &quot; Mal… No Yes Caucasian ## 10 36.5 6386 469 4 79 6 &quot;Fema… No Yes Caucasian ## # … with 1 more variable: Balance &lt;int&gt; TODO: skimr::skim(crdt_trn), str(crdt_trn), View(crdt_trn) crdt_trn %&gt;% ggplot(aes(x = Rating)) + geom_histogram(bins = 20) mod = lm(formula = Rating ~ ., data = crdt_trn) sqrt(mean((predict(mod, crdt_tst) - crdt_tst$Rating) ^ 2)) ## [1] 9.998283 sd(crdt_trn$Rating) ## [1] 153.821 6.14 Source R Markdown: 06-linear-regression.Rmd "],
["the-backlog.html", "A The Backlog A.1 Sorted A.2 Unsorted A.3 Source", " A The Backlog The backlog will contain a list of topics of discussion that have arisen during the semester that we will return to if there is time. A.1 Sorted Why are we so darn focused on means? https://www.benkuhn.net/squared https://news.ycombinator.com/item?id=9556459 A.2 Unsorted https://atrebas.github.io/post/2019-01-15-2018-learning/ Don’t load previous worksapce. (Screenshot of this option in RStudio.) A.3 Source R Markdown: 98-backlog.Rmd "]
]
